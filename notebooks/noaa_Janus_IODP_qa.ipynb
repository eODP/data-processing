{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA NOAA Janus IODP metadata\n",
    "\n",
    "Get basic metadata (file names, column names) about NOAA Janus IODP dataset. Create csv that lists all the files.\n",
    "\n",
    "NOAA_csv/JanusIODP_paleo_agemodel  \n",
    "expedition 101-210 \n",
    "taxa 101-210, age models 101-190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from normalize_noaa_files import (\n",
    "    unique_filenames_for_paths,\n",
    "    unique_columns_for_paths,\n",
    "    filename_index,\n",
    "    format_filepaths_set,\n",
    "    qa_files_for_paths,\n",
    "    column_counts_for_paths\n",
    ")\n",
    "import space_delim as sd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = 'cleaned_data'\n",
    "base_data_path = os.path.join(base_directory, 'NOAA_csv', 'JanusIODP_paleo_agemodel')\n",
    "metadata_path = os.path.join(base_directory, 'metadata', 'noaa_janus_iodp_files.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files 2481\n"
     ]
    }
   ],
   "source": [
    "csv_paths = glob.glob(os.path.join(base_data_path, 'paleontology', '**', '**', '**', '**', '*.csv'))\n",
    "print('files', len(csv_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files 2045\n"
     ]
    }
   ],
   "source": [
    "taxa_csv_paths = [path for path in csv_paths if 'range_tables' in path] \n",
    "print('files', len(taxa_csv_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files 436\n"
     ]
    }
   ],
   "source": [
    "age_csv_paths = [path for path in csv_paths if 'age_models' in path]\n",
    "print('files', len(age_csv_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unique file names\n",
    "\n",
    "Get all the file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Benthic Foraminifers.csv',\n",
       " 'Benthic_Foraminifers.csv',\n",
       " 'Bolboforms.csv',\n",
       " 'Diatoms.csv',\n",
       " 'Dinoflagellates_Acritarch_Prasinophytes.csv',\n",
       " 'Dinoflagellates_Acritarchs_Prasinophytes.csv',\n",
       " 'Macrofossils.csv',\n",
       " 'Miscellaneous.csv',\n",
       " 'Nannofossils .csv',\n",
       " 'Nannofossils.csv',\n",
       " 'Ostracodes.csv',\n",
       " 'Planktonic Foraminifers.csv',\n",
       " 'Planktonic_Foraminifers .csv',\n",
       " 'Planktonic_Foraminifers.csv',\n",
       " 'Pollen_Spores.csv',\n",
       " 'Pteropods.csv',\n",
       " 'Radiolarians.csv',\n",
       " 'Silicoflagellates_Ebridians_Actiniscidians.csv',\n",
       " 'Sponge_Spicules.csv',\n",
       " 'Trace_Fossils.csv'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_filenames_for_paths(taxa_csv_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age_Model_Initial_Report.csv',\n",
       " 'Age_Model_Initial_Reports.csv',\n",
       " 'Age_Model_Post_Moratorium.csv',\n",
       " 'Age_Model_Shipboard.csv',\n",
       " 'Age_Model_Shipboard_Report.csv'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_filenames_for_paths(age_csv_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA ODP paleo files\n",
    "\n",
    "Count the number of good files vs bad files that need to be fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_fields = {\n",
    "    'Data',\n",
    "    'Age From (oldest)',\n",
    "    'Age To (youngest)',\n",
    "    'Zone From (bottom)',\n",
    "    'Zone To  (top)',\n",
    "    'Leg',\n",
    "    'Site',\n",
    "    'H',\n",
    "    'Cor',\n",
    "    'T',\n",
    "    'Sc',\n",
    "    'Top(cm)',\n",
    "    'Depth (mbsf)',\n",
    "    'Scientist',\n",
    "#     'Fossil Group',\n",
    "    'Comment', \n",
    "    'Group Abundance',\n",
    "    'Group Preservation'\n",
    "}\n",
    "\n",
    "results = qa_files_for_paths(taxa_csv_paths, expected_fields, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad_tabs 0\n",
      "bad_encoding 0\n",
      "space_delim 0\n",
      "missing_fields 0\n",
      "good_files 2045\n"
     ]
    }
   ],
   "source": [
    "print('bad_tabs', len(results['bad_tabs']))\n",
    "print('bad_encoding', len(results['bad_encoding']))\n",
    "print('space_delim', len(results['space_delim']))\n",
    "print('missing_fields', len(results['missing_fields']))\n",
    "print('good_files', len(results['good_files']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['missing_fields']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process latin_encoding\n",
    "handle files with encoding that isn't utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in results['bad_encoding']:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert file to utf-8 encoding\n",
    "https://codereview.stackexchange.com/a/202985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in results['bad_encoding']:\n",
    "    with open(file, 'rb') as f:\n",
    "        content_bytes = f.read()\n",
    "    detected = chardet.detect(content_bytes)\n",
    "    encoding = detected['encoding']\n",
    "    content_text = content_bytes.decode(encoding)\n",
    "    \n",
    "    with open(file, 'w', encoding='utf-8') as f:\n",
    "        f.write(content_text)\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process bad_tabs\n",
    "handle files where the hearers and rows have different number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in results['bad_tabs']:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process space_delim\n",
    "\n",
    "handle files that use random number of spaces to separate the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in results['space_delim']:\n",
    "    file_size = os.path.getsize(file)\n",
    "    print(f'\"{file}\",')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process missing_fields\n",
    "\n",
    "handle files don't have the expected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in results['missing_fields']:\n",
    "    print(file)\n",
    "    df = pd.read_csv(file, nrows=1)\n",
    "    print(expected_fields - set(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check space_delim files were correctly fixed\n",
    "\n",
    "After converting space delimited files, check the  files for errors. Errors\n",
    "include values that have spaces or columns that have no values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Preservation: has no values\n",
      "cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/181/1119/HOLE_B/Diatoms.csv\n",
      "---\n",
      "Group Preservation: has no values\n",
      "cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/181/1119/HOLE_C/Diatoms.csv\n",
      "---\n",
      "Group Preservation: has no values\n",
      "cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/181/1119/HOLE_A/Diatoms.csv\n",
      "---\n",
      "Group Preservation: has no values\n",
      "cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/181/1120/HOLE_B/Diatoms.csv\n",
      "---\n",
      "Group Abundance: has no values\n",
      "cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/181/1120/HOLE_B/Diatoms.csv\n",
      "---\n",
      "Group Preservation: has no values\n",
      "cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/181/1120/HOLE_D/Diatoms.csv\n",
      "---\n",
      "Group Abundance: has no values\n",
      "cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/181/1120/HOLE_D/Diatoms.csv\n",
      "---\n",
      "Group Preservation: has no values\n",
      "cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/181/1120/HOLE_A/Diatoms.csv\n",
      "---\n",
      "Group Abundance: has no values\n",
      "cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/181/1120/HOLE_A/Diatoms.csv\n",
      "---\n",
      "Zone To (top): has no values\n",
      "cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/172/1056/HOLE_C/Nannofossils.csv\n",
      "---\n",
      "Zone To (top): has no values\n",
      "cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/174/1071/HOLE_B/Planktonic_Foraminifers.csv\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "fixed_space_delim_files = (\n",
    "    sd.space_delim_files_janus_iodp_1\n",
    "    + sd.space_delim_files_janus_iodp_2\n",
    "    + sd.space_delim_files_janus_iodp_3\n",
    ")\n",
    "\n",
    "skip_fields = {\n",
    "    'Data', 'Age From (oldest)', 'Age To (youngest)', 'Zone From (bottom)', \n",
    "    'Zone To  (top)', 'Leg', 'Site','H', 'Cor', 'T', 'Sc', 'Top(cm)', \n",
    "    'Depth (mbsf)', 'Scientist', 'Comment', 'Fossil Group'\n",
    "}\n",
    "\n",
    "def valid_values(x):\n",
    "    return isinstance(x, str) and ' ' in x\n",
    "\n",
    "for file in fixed_space_delim_files:\n",
    "    filename = os.path.join(\"cleaned_data\", file)\n",
    "\n",
    "    df = pd.read_csv(filename, dtype=str)\n",
    "    df.dropna(axis=\"columns\", how=\"all\")\n",
    "    \n",
    "    taxa_columns = set(df.columns) - skip_fields\n",
    "    for col in taxa_columns:\n",
    "        # check if there are values with spaces         \n",
    "        if sum(df[col].apply(valid_values)) > 0:\n",
    "            print(f'{col}: has space')\n",
    "            print(filename)\n",
    "            print('---')\n",
    "            \n",
    "        # check if column is blank       \n",
    "        if df[col].isnull().values.all():\n",
    "            print(f'{col}: has no values')\n",
    "            print(filename)\n",
    "            print('---')\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## file list\n",
    "\n",
    "Create csv that lists all the files for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "switch = {\n",
    "    'Benthic Foraminifers.csv': 'benthic_foraminfera',\n",
    "    'Benthic_Foraminifers.csv': 'benthic_foraminfera',\n",
    "    'Bolboforms.csv': 'bolboformids',\n",
    "    'Diatoms.csv': 'diatoms',\n",
    "    'Dinoflagellates_Acritarch_Prasinophytes.csv': 'dinoflagellates/acritarchs/prasinophytes',\n",
    "    'Dinoflagellates_Acritarchs_Prasinophytes.csv': 'dinoflagellates/acritarchs/prasinophytes',\n",
    "    'Nannofossils .csv': 'nannofossils',\n",
    "    'Nannofossils.csv': 'nannofossils',\n",
    "    'Ostracodes.csv': 'ostracods',\n",
    "    'Planktonic Foraminifers.csv': 'planktic_foraminfera',\n",
    "    'Planktonic_Foraminifers .csv': 'planktic_foraminfera',\n",
    "    'Planktonic_Foraminifers.csv': 'planktic_foraminfera',\n",
    "    'Pollen_Spores.csv': 'pollen',\n",
    "    'Pteropods.csv': 'pteropods',\n",
    "    'Radiolarians.csv': 'radiolarians',\n",
    "    'Silicoflagellates_Ebridians_Actiniscidians.csv': 'silicoflagellates/ebridians/actiniscidians',\n",
    "    'Sponge_Spicules.csv': 'sponge_spicules',\n",
    "    'Trace_Fossils.csv': 'trace_fossils'\n",
    "}\n",
    "index = filename_index(csv_paths[0])\n",
    "\n",
    "for path in csv_paths:\n",
    "    file_data = {}\n",
    "    parts = Path(path).parts\n",
    "    filename = parts[index]    \n",
    "    \n",
    "    file_data['path'] = path\n",
    "    \n",
    "    if filename.startswith('Age_'):\n",
    "        type = 'age'\n",
    "    else:\n",
    "        type = 'taxa'\n",
    "    file_data['type'] = type\n",
    "    \n",
    "    if type == 'taxa':\n",
    "        file_data['taxon_group'] = switch.get(filename, np.nan)\n",
    "    \n",
    "    file_data['expedition'] = parts[5]\n",
    "    file_data['site'] = parts[6]\n",
    "\n",
    "    \n",
    "    file_list.append(file_data)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>type</th>\n",
       "      <th>expedition</th>\n",
       "      <th>site</th>\n",
       "      <th>taxon_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel...</td>\n",
       "      <td>age</td>\n",
       "      <td>135</td>\n",
       "      <td>835</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel...</td>\n",
       "      <td>age</td>\n",
       "      <td>135</td>\n",
       "      <td>834</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel...</td>\n",
       "      <td>age</td>\n",
       "      <td>135</td>\n",
       "      <td>834</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel...</td>\n",
       "      <td>age</td>\n",
       "      <td>135</td>\n",
       "      <td>841</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel...</td>\n",
       "      <td>age</td>\n",
       "      <td>135</td>\n",
       "      <td>841</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path type expedition site  \\\n",
       "0  cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel...  age        135  835   \n",
       "1  cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel...  age        135  834   \n",
       "2  cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel...  age        135  834   \n",
       "3  cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel...  age        135  841   \n",
       "4  cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel...  age        135  841   \n",
       "\n",
       "  taxon_group  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(file_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(metadata_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## column names\n",
    "\n",
    "Get all the column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### age models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'    Age (Ma)',\n",
       " 'Age Model Type           ',\n",
       " 'Control Point Comment',\n",
       " 'Depth (mbsf)',\n",
       " 'H',\n",
       " 'Leg',\n",
       " 'Site',\n",
       " 'Unnamed: 6'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_columns = unique_columns_for_paths(age_csv_paths)\n",
    "age_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7, 8}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_counts_for_paths(age_csv_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print out files that have too many columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/age_models/150/906/HOLE_A/Age_Model_Initial_Report.csv\n",
      "cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/age_models/154/925/HOLE_A/Age_Model_Initial_Report.csv\n"
     ]
    }
   ],
   "source": [
    "for path in age_csv_paths:\n",
    "    df = pd.read_csv(path, nrows=0)\n",
    "    if len(df.columns) == 8:\n",
    "        print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12976"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxa_columns = unique_columns_for_paths(taxa_csv_paths)\n",
    "len(taxa_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## files grouped by expedition and file type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = {}\n",
    "index = filename_index(path)\n",
    "\n",
    "for path in csv_paths:\n",
    "    parts = Path(path).parts\n",
    "    exp = parts[5]\n",
    "    filename = parts[index]\n",
    "        \n",
    "    if exp not in contents:\n",
    "        contents[exp] = {'taxa': set(),'age_model': set()}\n",
    "        \n",
    "    if filename.startswith('Age_'):\n",
    "        contents[exp]['age_model'].add(filename)\n",
    "    else:\n",
    "        contents[exp]['taxa'].add(filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "\n",
    "for exp in contents.items():\n",
    "    file_data = {}\n",
    "    file_data['expedition'] = exp[0]\n",
    "    file_data['taxa'] = format_filepaths_set(exp[1], 'taxa')\n",
    "    file_data['age_model'] = format_filepaths_set(exp[1], 'age_model')\n",
    "\n",
    "    file_list.append(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expedition</th>\n",
       "      <th>taxa</th>\n",
       "      <th>age_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>Nannofossils.csv,Planktonic_Foraminifers.csv,B...</td>\n",
       "      <td>Age_Model_Initial_Report.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104</td>\n",
       "      <td>Ostracodes.csv,Macrofossils.csv,Planktonic_For...</td>\n",
       "      <td>Age_Model_Initial_Reports.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>168</td>\n",
       "      <td>Nannofossils.csv</td>\n",
       "      <td>Age_Model_Initial_Report.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>157</td>\n",
       "      <td>Nannofossils.csv,Planktonic_Foraminifers.csv</td>\n",
       "      <td>Age_Model_Initial_Report.csv,Age_Model_Shipboa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>Dinoflagellates_Acritarch_Prasinophytes.csv,Na...</td>\n",
       "      <td>Age_Model_Initial_Report.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  expedition                                               taxa  \\\n",
       "0        135  Nannofossils.csv,Planktonic_Foraminifers.csv,B...   \n",
       "1        104  Ostracodes.csv,Macrofossils.csv,Planktonic_For...   \n",
       "2        168                                   Nannofossils.csv   \n",
       "3        157       Nannofossils.csv,Planktonic_Foraminifers.csv   \n",
       "4        150  Dinoflagellates_Acritarch_Prasinophytes.csv,Na...   \n",
       "\n",
       "                                           age_model  \n",
       "0                       Age_Model_Initial_Report.csv  \n",
       "1                      Age_Model_Initial_Reports.csv  \n",
       "2                       Age_Model_Initial_Report.csv  \n",
       "3  Age_Model_Initial_Report.csv,Age_Model_Shipboa...  \n",
       "4                       Age_Model_Initial_Report.csv  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(file_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('tmp', 'noaa_janus_iodp_grouped_files.csv')\n",
    "df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous.csv\n",
    "\n",
    "create github link for each Miscellaneous.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/eODP/data-processing/tree/master/notebooks/cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/104/643/HOLE_A/Miscellaneous.csv\n",
      "https://github.com/eODP/data-processing/tree/master/notebooks/cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/104/644/HOLE_A/Miscellaneous.csv\n",
      "https://github.com/eODP/data-processing/tree/master/notebooks/cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/104/642/HOLE_B/Miscellaneous.csv\n",
      "https://github.com/eODP/data-processing/tree/master/notebooks/cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/120/747/HOLE_A/Miscellaneous.csv\n",
      "https://github.com/eODP/data-processing/tree/master/notebooks/cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/120/749/HOLE_B/Miscellaneous.csv\n",
      "https://github.com/eODP/data-processing/tree/master/notebooks/cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/120/749/HOLE_C/Miscellaneous.csv\n",
      "https://github.com/eODP/data-processing/tree/master/notebooks/cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/120/748/HOLE_B/Miscellaneous.csv\n",
      "https://github.com/eODP/data-processing/tree/master/notebooks/cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/120/748/HOLE_C/Miscellaneous.csv\n",
      "https://github.com/eODP/data-processing/tree/master/notebooks/cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/120/751/HOLE_A/Miscellaneous.csv\n",
      "https://github.com/eODP/data-processing/tree/master/notebooks/cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/120/750/HOLE_A/Miscellaneous.csv\n",
      "https://github.com/eODP/data-processing/tree/master/notebooks/cleaned_data/NOAA_csv/JanusIODP_paleo_agemodel/paleontology/range_tables/119/744/HOLE_A/Miscellaneous.csv\n"
     ]
    }
   ],
   "source": [
    "for path in csv_paths:\n",
    "    if 'Miscellaneous.csv' in path:\n",
    "        link = 'https://github.com/eODP/data-processing/tree/master/notebooks/' + '/'.join(path.split('/'))\n",
    "        print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
