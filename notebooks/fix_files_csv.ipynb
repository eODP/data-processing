{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix files that were processed incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from normalize_data import (\n",
    "    check_duplicate_columns,\n",
    "    normalize_expedition_section_cols,\n",
    "    csv_cleanup,\n",
    "    create_sample_cols,\n",
    "    update_metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology = 'cleaned_data/Lithology_CSV'\n",
    "lithology_meta = 'cleaned_data/metadata/Lithology_changes.csv'\n",
    "\n",
    "micropal_1 = 'cleaned_data/Micropal_CSV_1'\n",
    "micropal_meta_1 = 'cleaned_data/metadata/Micropal_1_changes.csv'\n",
    "\n",
    "micropal_2 = 'cleaned_data/Micropal_CSV_2'\n",
    "micropal_meta_2 = 'cleaned_data/metadata/Micropal_2_changes.csv'\n",
    "\n",
    "micropal_3 = 'cleaned_data/Micropal_CSV_3'\n",
    "micropal_meta_3 = 'cleaned_data/metadata/Micropal_3_changes.csv'\n",
    "\n",
    "micropal_revised = 'cleaned_data/Micropal_CSV_revised'\n",
    "\n",
    "all_LIMS = [lithology, micropal_1, micropal_2, micropal_3, micropal_revised]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_path = micropal_3\n",
    "metadata_file = micropal_meta_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fix exp..aw columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refactor regex matching to better extract exp...aw columns from the sample name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>taxon_group</th>\n",
       "      <th>add_expedition_section_cols</th>\n",
       "      <th>update_sample_col</th>\n",
       "      <th>update_top_bottom</th>\n",
       "      <th>add_missing_cols</th>\n",
       "      <th>clean_up_taxa_values</th>\n",
       "      <th>fix_expedition_aw_cols</th>\n",
       "      <th>add_extra_sample_data</th>\n",
       "      <th>clean_up_taxa_metadata_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>339_benthic_forams_U1388B_5.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324_U1348A_benthic_forams.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>339_planktic_forams_U1387C.csv</td>\n",
       "      <td>planktic_forams</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>339_benthic_forams_U1390A_6.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>341_radiolarians_U1419D.csv</td>\n",
       "      <td>radiolarians</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              file      taxon_group  \\\n",
       "0  339_benthic_forams_U1388B_5.csv   benthic_forams   \n",
       "1    324_U1348A_benthic_forams.csv   benthic_forams   \n",
       "2   339_planktic_forams_U1387C.csv  planktic_forams   \n",
       "3  339_benthic_forams_U1390A_6.csv   benthic_forams   \n",
       "4      341_radiolarians_U1419D.csv     radiolarians   \n",
       "\n",
       "   add_expedition_section_cols  update_sample_col  update_top_bottom  \\\n",
       "0                        False              False               True   \n",
       "1                        False               True               True   \n",
       "2                        False              False               True   \n",
       "3                        False              False               True   \n",
       "4                         True              False              False   \n",
       "\n",
       "   add_missing_cols  clean_up_taxa_values  fix_expedition_aw_cols  \\\n",
       "0             False                 False                   False   \n",
       "1             False                  True                   False   \n",
       "2             False                 False                   False   \n",
       "3             False                 False                   False   \n",
       "4             False                  True                    True   \n",
       "\n",
       "   add_extra_sample_data  clean_up_taxa_metadata_values  \n",
       "0                  False                          False  \n",
       "1                  False                           True  \n",
       "2                  False                          False  \n",
       "3                  False                          False  \n",
       "4                  False                           True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(metadata_file)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_metadata = metadata[metadata['add_expedition_section_cols'] == True]\n",
    "filtered_metadata = filtered_metadata['file'].to_list()\n",
    "len(filtered_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_expedition_section_cols(df):\n",
    "    \"\"\" Create Exp...Section columns using Sample or Label ID \"\"\"\n",
    "    if \"Sample\" in df.columns:\n",
    "        new_df = create_sample_cols(df[\"Sample\"])\n",
    "    elif \"Label ID\" in df.columns:\n",
    "        new_df = create_sample_cols(df[\"Label ID\"])\n",
    "    else:\n",
    "        raise ValueError(\"File does not have the expected columns.\")\n",
    "        \n",
    "    df['Exp'] = new_df['Exp']\n",
    "    df['Site'] = new_df['Site']\n",
    "    df['Hole'] = new_df['Hole']\n",
    "    df['Core'] = new_df['Core']\n",
    "    df['Type'] = new_df['Type']\n",
    "    df['Section'] = new_df['Section']\n",
    "    df['A/W'] = new_df['A/W']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_filename(file):\n",
    "    changed = False\n",
    "    if file in filtered_metadata:\n",
    "        path = f\"{clean_data_path}/{file}\"\n",
    "        content = pd.read_csv(path, dtype=str)\n",
    "\n",
    "\n",
    "        original = pd.DataFrame(content['A/W'])\n",
    "        content = fix_expedition_section_cols(content)\n",
    "\n",
    "        changed = not original['A/W'].equals(content['A/W'])\n",
    "\n",
    "        if changed:\n",
    "            content = csv_cleanup(content, path)\n",
    "            content.to_csv(path, index=False)\n",
    "        \n",
    "    return changed\n",
    "\n",
    "change_columns = [process_filename(file) for file in metadata['file']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>taxon_group</th>\n",
       "      <th>add_expedition_section_cols</th>\n",
       "      <th>update_sample_col</th>\n",
       "      <th>update_top_bottom</th>\n",
       "      <th>add_missing_cols</th>\n",
       "      <th>clean_up_taxa_values</th>\n",
       "      <th>fix_expedition_aw_cols</th>\n",
       "      <th>add_extra_sample_data</th>\n",
       "      <th>clean_up_taxa_metadata_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>339_benthic_forams_U1388B_5.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324_U1348A_benthic_forams.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>339_planktic_forams_U1387C.csv</td>\n",
       "      <td>planktic_forams</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>339_benthic_forams_U1390A_6.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>341_radiolarians_U1419D.csv</td>\n",
       "      <td>radiolarians</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              file      taxon_group  \\\n",
       "0  339_benthic_forams_U1388B_5.csv   benthic_forams   \n",
       "1    324_U1348A_benthic_forams.csv   benthic_forams   \n",
       "2   339_planktic_forams_U1387C.csv  planktic_forams   \n",
       "3  339_benthic_forams_U1390A_6.csv   benthic_forams   \n",
       "4      341_radiolarians_U1419D.csv     radiolarians   \n",
       "\n",
       "   add_expedition_section_cols  update_sample_col  update_top_bottom  \\\n",
       "0                        False              False               True   \n",
       "1                        False               True               True   \n",
       "2                        False              False               True   \n",
       "3                        False              False               True   \n",
       "4                         True              False              False   \n",
       "\n",
       "   add_missing_cols  clean_up_taxa_values  fix_expedition_aw_cols  \\\n",
       "0             False                 False                   False   \n",
       "1             False                  True                   False   \n",
       "2             False                 False                   False   \n",
       "3             False                 False                   False   \n",
       "4             False                  True                    True   \n",
       "\n",
       "   add_extra_sample_data  clean_up_taxa_metadata_values  \n",
       "0                  False                          False  \n",
       "1                  False                           True  \n",
       "2                  False                          False  \n",
       "3                  False                          False  \n",
       "4                  False                           True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\"fix_expedition_aw_cols\": change_columns}\n",
    "new_metadata = update_metadata(metadata, dict)\n",
    "new_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata.to_csv(metadata_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix sample name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add 'Extra Sample ID Data' when creating the sample name from Exp...A/W columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_path = micropal_3\n",
    "metadata_file = micropal_meta_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(metadata_file)\n",
    "filtered_files = metadata[metadata['update_sample_col'] == True]['file'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_extra_sample_data(row, columns):\n",
    "    if columns[0] == 'Sample':\n",
    "        return row['Sample']\n",
    "    elif columns[1] == 'Sample':\n",
    "        return row['Sample']\n",
    "    elif 'Extra Sample ID Data' not in columns:\n",
    "        return row['Sample']\n",
    "    elif row['Extra Sample ID Data'] is None:\n",
    "        return row['Sample']\n",
    "    elif row['Extra Sample ID Data'] is np.NaN:\n",
    "        return row['Sample']\n",
    "    \n",
    "    if row['A/W'] == 'PAL':\n",
    "        return row['Sample'] + '-' + row['Extra Sample ID Data'] \n",
    "    else:\n",
    "        return row['Sample'] + ' ' + row['Extra Sample ID Data'] \n",
    "    \n",
    "def process_filename(file, filtered_files):\n",
    "    changed = False\n",
    "    if file in filtered_files:\n",
    "        path = f\"{clean_data_path}/{file}\"\n",
    "        content = pd.read_csv(path, dtype=str)\n",
    "\n",
    "        columns = content.columns\n",
    "\n",
    "        original = pd.DataFrame(content['Sample'])\n",
    "\n",
    "        content['Sample'] = content.apply(lambda row: add_extra_sample_data(row, columns), axis=1)\n",
    "        \n",
    "        changed = not original['Sample'].equals(content['Sample'])\n",
    "        \n",
    "        if changed:\n",
    "            content = csv_cleanup(content, path)\n",
    "            content.to_csv(path, index=False)\n",
    "\n",
    "    return changed\n",
    "\n",
    "change_columns = [process_filename(file, filtered_files) for file in metadata['file']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>taxon_group</th>\n",
       "      <th>add_expedition_section_cols</th>\n",
       "      <th>update_sample_col</th>\n",
       "      <th>update_top_bottom</th>\n",
       "      <th>add_missing_cols</th>\n",
       "      <th>clean_up_taxa_values</th>\n",
       "      <th>fix_expedition_aw_cols</th>\n",
       "      <th>add_extra_sample_data</th>\n",
       "      <th>clean_up_taxa_metadata_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>339_benthic_forams_U1388B_5.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324_U1348A_benthic_forams.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>339_planktic_forams_U1387C.csv</td>\n",
       "      <td>planktic_forams</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>339_benthic_forams_U1390A_6.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>341_radiolarians_U1419D.csv</td>\n",
       "      <td>radiolarians</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              file      taxon_group  \\\n",
       "0  339_benthic_forams_U1388B_5.csv   benthic_forams   \n",
       "1    324_U1348A_benthic_forams.csv   benthic_forams   \n",
       "2   339_planktic_forams_U1387C.csv  planktic_forams   \n",
       "3  339_benthic_forams_U1390A_6.csv   benthic_forams   \n",
       "4      341_radiolarians_U1419D.csv     radiolarians   \n",
       "\n",
       "   add_expedition_section_cols  update_sample_col  update_top_bottom  \\\n",
       "0                        False              False               True   \n",
       "1                        False               True               True   \n",
       "2                        False              False               True   \n",
       "3                        False              False               True   \n",
       "4                         True              False              False   \n",
       "\n",
       "   add_missing_cols  clean_up_taxa_values  fix_expedition_aw_cols  \\\n",
       "0             False                 False                   False   \n",
       "1             False                  True                   False   \n",
       "2             False                 False                   False   \n",
       "3             False                 False                   False   \n",
       "4             False                  True                    True   \n",
       "\n",
       "   add_extra_sample_data  clean_up_taxa_metadata_values  \n",
       "0                  False                          False  \n",
       "1                  False                           True  \n",
       "2                  False                          False  \n",
       "3                  False                          False  \n",
       "4                  False                           True  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\"add_extra_sample_data\": change_columns}\n",
    "new_metadata = update_metadata(metadata, dict)\n",
    "new_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata.to_csv(metadata_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove empty rows and columns\n",
    "\n",
    "remove empty rows and columns without headers or data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_rows_cols = []\n",
    "\n",
    "for directory in all_LIMS:\n",
    "    paths = glob.glob(f\"{directory}/*.csv\")\n",
    "\n",
    "    for path in paths:\n",
    "        df = pd.read_csv(path, dtype=str, header=None)\n",
    "        orginal_dim = df.shape\n",
    "        new_df = df.dropna(axis=\"index\", how=\"all\").copy()\n",
    "        new_df.dropna(axis=\"columns\", how=\"all\", inplace=True)\n",
    "        new_dim = new_df.shape\n",
    "        \n",
    "        if orginal_dim != new_dim:\n",
    "            new_df.to_csv(path, index=False, header=False)\n",
    "            empty_rows_cols.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(empty_rows_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'files with empty rows or columns': empty_rows_cols})\n",
    "df.to_csv('cleaned_data/metadata/lims_empty_rows_cols.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicate identical rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "\n",
    "for clean_data_path in all_LIMS:\n",
    "    raw_csvs = glob.glob(f\"{clean_data_path}/*.csv\")\n",
    "    \n",
    "    for path in raw_csvs:\n",
    "        content = pd.read_csv(path, dtype=str)\n",
    "        content.dropna(inplace=True, axis='index', how='all')\n",
    "        original_rows = len(content)\n",
    "        content.drop_duplicates(inplace=True)\n",
    "        new_rows = len(content)\n",
    "        \n",
    "        if original_rows != new_rows:\n",
    "            content = csv_cleanup(content, path)\n",
    "            content.to_csv(path, index=False)\n",
    "            files.append(path)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'files with identical rows': files})\n",
    "df.to_csv('cleaned_data/metadata/lims_identical_rows.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resave each file\n",
    "Open and resave each file to get rid of weird starting character and ending character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in all_LIMS:\n",
    "    raw_csvs = glob.glob(f\"{directory}/*.csv\")\n",
    "\n",
    "    for path in raw_csvs:\n",
    "        df = pd.read_csv(path, dtype=str)\n",
    "        df = csv_cleanup(df, path)\n",
    "        df.to_csv(path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
