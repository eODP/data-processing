{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA LIMS files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some basic QA on the LIMS files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "import glob\n",
    "import shutil\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from normalize_data import (\n",
    "    check_duplicate_columns,\n",
    "    extract_taxon_group_from_filename,\n",
    "    csv_cleanup,\n",
    "    create_sample_name_for_row\n",
    "    \n",
    ")\n",
    "\n",
    "sys.path.append('../')\n",
    "import db "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMS_lith_paths = [\n",
    "    os.path.join('cleaned_data', 'Lithology_CSV')\n",
    "]\n",
    "\n",
    "LIMS_paleo_paths = [\n",
    "    os.path.join('cleaned_data', 'Micropal_CSV_1'),\n",
    "    os.path.join('cleaned_data', 'Micropal_CSV_2'),\n",
    "    os.path.join('cleaned_data', 'Micropal_CSV_3'),\n",
    "    os.path.join('cleaned_data', 'Micropal_CSV_revised'),\n",
    "]\n",
    "\n",
    "LIMS_paths = LIMS_lith_paths + LIMS_paleo_paths\n",
    "\n",
    "\n",
    "taxa_meta = os.path.join('cleaned_data', 'metadata', 'LIMS', 'Micropal_changes.csv')\n",
    "lith_meta = os.path.join('cleaned_data', 'metadata', 'LIMS', 'Lithology_changes.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## duplicate column names\n",
    "\n",
    "check if csv has duplicate column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_columns(directories, file_extension='csv'):\n",
    "    for directory in directories:\n",
    "        raw_csvs = glob.glob(f\"{directory}/**/*.{file_extension}\", recursive=True)\n",
    "\n",
    "        for path in raw_csvs:\n",
    "            content = pd.read_csv(path)\n",
    "            content.dropna(inplace=True, axis='columns', how='all')\n",
    "\n",
    "            check_duplicate_columns(content, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_data/Micropal_CSV_3/341_benthic_forams_U1417B.csv, Type: duplicate columns have different values\n"
     ]
    }
   ],
   "source": [
    "path='cleaned_data/Micropal_CSV_3/341_benthic_forams_U1417B.csv'\n",
    "content = pd.read_csv(path)\n",
    "content.dropna(inplace=True, axis='columns', how='all')\n",
    "\n",
    "df = check_duplicate_columns(content, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIMS: Leg 317 - present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_data/Lithology_CSV/323 Core Description Template_U1341A.csv, GRAVEL SIZE CLAST: duplicate columns have different values\n",
      "cleaned_data/Micropal_CSV_3/341_benthic_forams_U1417B.csv, Type: duplicate columns have different values\n"
     ]
    }
   ],
   "source": [
    "duplicate_columns(LIMS_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Janus: Leg 130 - 312"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOAA: Leg 1 - 129"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for files that contain certain headers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    'COLOR',\n",
    "    'Clast color',\n",
    "    'Color',\n",
    "    'Color (name)',\n",
    "    'Color code',\n",
    "    'Color(name)',\n",
    "    'LITH 1 color',\n",
    "    'LITH 2 color',\n",
    "    'Lithology color',\n",
    "    'Lithology color (Munsell)',\n",
    "    'Lithology color (simple)',\n",
    "    'MAJ Lith. color',\n",
    "    'MAJ Lithology color',\n",
    "    'MAJ lith color (simple)',\n",
    "    'MIN Lith. color',\n",
    "    'MIN lith color (simple)'\n",
    "}\n",
    "\n",
    "zones = {\n",
    "    'Zone name',\n",
    "    'Zone name (short)'\n",
    "}\n",
    "\n",
    "keywords = zones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "process all files in a directory on disks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clean_data_path in LIMS_paleo_paths:\n",
    "    raw_csvs = glob.glob(f\"{clean_data_path}/*.csv\")\n",
    "\n",
    "    for path in raw_csvs:\n",
    "        df = pd.read_csv(path, dtype=str)\n",
    "        df.dropna(how=\"all\", axis=\"columns\", inplace=True)\n",
    "\n",
    "        if keywords.intersection(set(df.columns)):\n",
    "            pass\n",
    "#             url = 'https://github.com/eODP/data-processing/blob/master/notebooks/'\n",
    "#             print(path)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "process all files in a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_data/Micropal_CSV_1/363-U1487A-nannofossils.csv\n",
      "cleaned_data/Micropal_CSV_1/363-U1483A-nannofossils.csv\n",
      "cleaned_data/Micropal_CSV_1/363-U1489C-nannofossils.csv\n",
      "cleaned_data/Micropal_CSV_1/320_U1331C_Radiolarians_3.csv\n",
      "cleaned_data/Micropal_CSV_1/363-U1484A-nannofossils.csv\n",
      "cleaned_data/Micropal_CSV_1/363-U1482A-planktic_forams.csv\n",
      "cleaned_data/Micropal_CSV_1/363-U1482C-nannofossils.csv\n",
      "cleaned_data/Micropal_CSV_2/351_U1438E_radiolarians.csv\n",
      "cleaned_data/Micropal_CSV_2/353_U1448A_diatoms.csv\n",
      "cleaned_data/Micropal_CSV_2/353_U1446A_nannofossils.csv\n",
      "cleaned_data/Micropal_CSV_2/371_U1509A_nannofossils.csv\n",
      "cleaned_data/Micropal_CSV_2/351_U1438A_radiolarians.csv\n",
      "cleaned_data/Micropal_CSV_2/354_U1451B_planktic_forams.csv\n",
      "cleaned_data/Micropal_CSV_2/356-U1462C_planktic_forams.csv\n",
      "cleaned_data/Micropal_CSV_2/354_U1451A_planktic_forams.csv\n",
      "cleaned_data/Micropal_CSV_2/371_U1510A_nannofossils.csv\n",
      "cleaned_data/Micropal_CSV_2/353_U1443B_diatoms.csv\n",
      "cleaned_data/Micropal_CSV_2/362_U1480E_diatoms.csv\n",
      "cleaned_data/Micropal_CSV_2/350_U1436B_planktic_forams.csv\n",
      "cleaned_data/Micropal_CSV_2/353_U1445A_diatoms.csv\n",
      "cleaned_data/Micropal_CSV_2/350_U1436C_planktic_forams.csv\n",
      "cleaned_data/Micropal_CSV_2/362_U1480F_nannofossils.csv\n",
      "cleaned_data/Micropal_CSV_2/356-U1463B_planktic_forams.csv\n",
      "cleaned_data/Micropal_CSV_2/353_U1447A_diatoms.csv\n",
      "cleaned_data/Micropal_CSV_2/351_U1438D_nannofossils.csv\n",
      "cleaned_data/Micropal_CSV_2/362_U1480G_diatoms.csv\n",
      "cleaned_data/Micropal_CSV_2/356-U1463B_nannofossils.csv\n",
      "cleaned_data/Micropal_CSV_2/371_U1511A_benthic_forams.csv\n",
      "cleaned_data/Micropal_CSV_2/371_U1506A_nannofossils.csv\n",
      "cleaned_data/Micropal_CSV_2/369_U1513B_nannofossils.csv\n",
      "cleaned_data/Micropal_CSV_2/356-U1461A_planktic_forams.csv\n",
      "cleaned_data/Micropal_CSV_2/356-U1459A_planktic_forams.csv\n",
      "cleaned_data/Micropal_CSV_2/354_U1449A_nannofossils.csv\n",
      "cleaned_data/Micropal_CSV_2/354_U1450A_nannofossils.csv\n",
      "cleaned_data/Micropal_CSV_2/356-U1459C_planktic_forams.csv\n",
      "cleaned_data/Micropal_CSV_2/353_U1443B_nannofossils.csv\n",
      "cleaned_data/Micropal_CSV_2/354_U1452B_planktic_forams.csv\n",
      "cleaned_data/Micropal_CSV_2/356-U1463B_benthic_forams.csv\n",
      "cleaned_data/Micropal_CSV_2/356-U1461D_planktic_forams.csv\n",
      "cleaned_data/Micropal_CSV_2/354_U1451A_nannofossils.csv\n",
      "cleaned_data/Micropal_CSV_2/355_U1456A_planktic_forams.csv\n",
      "cleaned_data/Micropal_CSV_2/356-U1458A_nannofossils.csv\n",
      "cleaned_data/Micropal_CSV_2/351_U1438B_radiolarians.csv\n",
      "cleaned_data/Micropal_CSV_2/350_U1436A_nannofossils.csv\n",
      "cleaned_data/Micropal_CSV_2/362_U1481A_diatoms.csv\n",
      "cleaned_data/Micropal_CSV_3/341_diatoms_U1418A.csv\n",
      "cleaned_data/Micropal_CSV_3/341_diatoms_U1418E.csv\n",
      "cleaned_data/Micropal_CSV_3/341_diatoms_U1419A.csv\n",
      "cleaned_data/Micropal_CSV_3/341_diatoms_U1418D.csv\n",
      "cleaned_data/Micropal_CSV_3/341_diatoms_U1419B.csv\n",
      "cleaned_data/Micropal_CSV_3/341_diatoms_U1419C.csv\n",
      "cleaned_data/Micropal_CSV_3/342_planktic_forams_U1406A_2.csv\n",
      "cleaned_data/Micropal_CSV_3/341_planktic_forams_U1420A.csv\n",
      "cleaned_data/Micropal_CSV_3/342_planktic_forams_U1408A_2.csv\n",
      "cleaned_data/Micropal_CSV_3/342_planktic_forams_U1407A_1.csv\n",
      "cleaned_data/Micropal_CSV_3/341_diatoms_U1417E.csv\n",
      "cleaned_data/Micropal_CSV_3/341_diatoms_U1417D.csv\n",
      "cleaned_data/Micropal_CSV_3/341_diatoms_U1417C.csv\n",
      "cleaned_data/Micropal_CSV_3/341_diatoms_U1417B.csv\n",
      "cleaned_data/Micropal_CSV_3/342_nannofossils_U1409A_2.csv\n",
      "cleaned_data/Micropal_CSV_3/342_planktic_forams_U1409A_1.csv\n",
      "cleaned_data/Micropal_CSV_3/341_radiolarians_U1417B.csv\n"
     ]
    }
   ],
   "source": [
    "metadata_path = 'tmp/csvs_with_duplicate_sample_names.csv'\n",
    "df = pd.read_csv(metadata_path)\n",
    "paths = list(df['path'].unique())\n",
    "\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path, dtype=str)\n",
    "    df.dropna(how=\"all\", axis=\"columns\", inplace=True)\n",
    "\n",
    "    if keywords.intersection(set(df.columns)):\n",
    "        print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cleaned_data/Micropal_CSV_1/363-U1487A-nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_1/363-U1483A-nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_1/363-U1489C-nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_1/320_U1331C_Radiolarians_3.csv',\n",
       " 'cleaned_data/Micropal_CSV_1/363-U1484A-nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_1/363-U1482A-planktic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_1/363-U1482C-nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_1/318_U1359A_Planktic_Forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_1/318_U1356A_Diatoms_1.csv',\n",
       " 'cleaned_data/Micropal_CSV_1/320_U1331B_Nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/346_U1430A_nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/374_U1525A_diatoms.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/351_U1438E_radiolarians.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/353_U1448A_diatoms.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/353_U1446A_nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/371_U1508B_radiolarians.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/371_U1509A_nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/351_U1438A_radiolarians.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/354_U1451B_planktic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/356-U1462C_planktic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/354_U1451A_planktic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/371_U1510A_nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/356-U1462C_benthic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/353_U1443B_diatoms.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/355_U1456A_diatoms.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/351_U1438D_benthic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/362_U1480E_diatoms.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/350_U1436B_planktic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/353_U1445A_diatoms.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/355_U1457B_diatoms.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/350_U1436C_planktic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/362_U1480F_nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/356-U1463B_planktic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/349_U1433B_radiolarians.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/361_U1474A_benthic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/353_U1447A_diatoms.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/351_U1438D_nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/362_U1480G_diatoms.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/350_U1437B_benthic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/356-U1463B_nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/371_U1511A_benthic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/371_U1506A_nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/346_U1425B_radiolarians_events.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/369_U1513B_nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/374_U1521A_diatoms.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/356-U1461A_planktic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/356-U1459A_planktic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/371_U1508A_radiolarians.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/346_U1430A_radiolarians.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/354_U1449A_nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/356-U1461B_benthic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/354_U1450A_nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/349_U1433A_planktic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/356-U1459C_planktic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/353_U1443B_nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/354_U1452B_planktic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/346_U1430C_benthic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/356-U1463B_benthic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/346_U1426A_planktic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/356-U1461D_planktic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/346_U1423A_planktic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/361_U1478A_diatoms.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/362_U1480G_radiolarians.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/354_U1451A_nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/355_U1456A_planktic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/356-U1458A_nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/351_U1438B_radiolarians.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/355_U1456C_diatoms.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/371_U1510A_radiolarians.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/350_U1436A_nannofossils.csv',\n",
       " 'cleaned_data/Micropal_CSV_2/362_U1481A_diatoms.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/341_diatoms_U1418A.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/340_benthic_forams_U1393A.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/342_planktic_forams_U1410A_2.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/341_diatoms_U1418E.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/341_diatoms_U1419A.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/341_diatoms_U1418D.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/341_diatoms_U1419B.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/341_diatoms_U1419C.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/344_U1381C_benthic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/342_radiolarians_U1403B.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/342_planktic_forams_U1406A_2.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/341_planktic_forams_U1420A.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/342_planktic_forams_U1406A_1.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/342_planktic_forams_U1405A.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/342_planktic_forams_U1408A_2.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/342_benthic_forams_U1410A_2.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/359_U1467A_radiolarians.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/342_planktic_forams_U1407A_1.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/330_nannofossils_U1377A.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/341_diatoms_U1417E.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/341_diatoms_U1417D.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/341_diatoms_U1417C.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/341_diatoms_U1417B.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/340_planktic_forams_U1394B.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/342_nannofossils_U1409A_2.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/321_U1337A_Planktic_forams.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/342_planktic_forams_U1409A_1.csv',\n",
       " 'cleaned_data/Micropal_CSV_3/341_radiolarians_U1417B.csv']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df['path'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'cleaned_data/Lithology_CSV/368_macroscopic_U1502A.csv'\n",
    "df = pd.read_csv(path, nrows=1)\n",
    "\n",
    "cols = [\n",
    "    'Sample', \n",
    "    'Top [cm]', \n",
    "    'Top Depth [m]', \n",
    "    'Bottom [cm]', \n",
    "    'Bottom Depth [m]', \n",
    "    'Extra Sample ID Data'\n",
    "]\n",
    "has_dups = sum(df.duplicated(subset = cols)) > 1\n",
    "        \n",
    "df.dropna(how=\"all\", axis=\"columns\", inplace=True)\n",
    "\n",
    "has_dups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## files with duplicate rows\n",
    "\n",
    "Files that have identical rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_rows =[]\n",
    "files_dup_rows = set()\n",
    "\n",
    "for clean_data_path in LIMS_paths:\n",
    "    raw_csvs = glob.glob(f\"{clean_data_path}/*.csv\")\n",
    "    \n",
    "    for path in raw_csvs:\n",
    "        content = pd.read_csv(path)\n",
    "        content.dropna(inplace=True, axis='index', how='all')\n",
    "        new_df = content[content.duplicated()]\n",
    "        \n",
    "        for index, row in new_df.iterrows():\n",
    "            dup_rows.append({'sample': row['Sample'], 'path': path})\n",
    "            files_dup_rows.add(path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dup_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_dup_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(dup_rows)\n",
    "new_df.to_csv('tmp/csvs_with_duplicate_rows.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiple expedition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clean_data_path in LIMS_paths:\n",
    "    raw_csvs = glob.glob(f\"{clean_data_path}/*.csv\")\n",
    "    \n",
    "    for path in raw_csvs:\n",
    "        pass\n",
    "#         df = pd.read_csv(path, dtype=str, usecols=['Exp'])\n",
    "#         if sum(df.duplicated())>0:\n",
    "#             print(path)\n",
    "            \n",
    "path = 'cleaned_data/Lithology_CSV/361_macroscopic_U1474D.csv'    \n",
    "df = pd.read_csv(path, dtype=str, usecols=['Exp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Exp'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing samples names\n",
    "\n",
    "Look for files that have rows with no sample names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_samples = set()\n",
    "\n",
    "for clean_data_path in LIMS_paths:\n",
    "    raw_csvs = glob.glob(f\"{clean_data_path}/*.csv\")\n",
    "\n",
    "    for path in raw_csvs:\n",
    "        content = pd.read_csv(path)\n",
    "        content.dropna(inplace=True, axis='index', how='all')\n",
    "        \n",
    "        if sum(content.isna()['Sample']) > 0:  \n",
    "            missing_samples.add(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"path\": list(missing_samples)})\n",
    "df.to_csv('tmp/csvs_with_missing_samples.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare lith row count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_csvs = glob.glob(f\"{LIMS_lith_paths[0]}/*.csv\")\n",
    "\n",
    "files = []\n",
    "\n",
    "for path in raw_csvs:\n",
    "    content = pd.read_csv(path, dtype=str)\n",
    "    files.append({\"file\": path.split('/')[2], \"original_count\": len(content)})\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>original_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>361_macroscopic_U1474D.csv</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>323 Core Description Template_U1341A.csv</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>361_macroscopic_U1479C.csv</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>340_sediment_U1393A.csv</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>339_sediment_U1386A.csv</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       file  original_count\n",
       "0                361_macroscopic_U1474D.csv             151\n",
       "1  323 Core Description Template_U1341A.csv             654\n",
       "2                361_macroscopic_U1479C.csv             254\n",
       "3                   340_sediment_U1393A.csv              20\n",
       "4                   339_sediment_U1386A.csv             592"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files\n",
    "df = pd.DataFrame(files)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(518, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_count</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>317_Lithostratigraphy_U1351A.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>499</td>\n",
       "      <td>317_Lithostratigraphy_U1351B.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>317_Lithostratigraphy_U1352A.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>740</td>\n",
       "      <td>317_Lithostratigraphy_U1352B.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>768</td>\n",
       "      <td>317_Lithostratigraphy_U1352C.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   db_count                              file\n",
       "0        49  317_Lithostratigraphy_U1351A.csv\n",
       "1       499  317_Lithostratigraphy_U1351B.csv\n",
       "2        75  317_Lithostratigraphy_U1352A.csv\n",
       "3       740  317_Lithostratigraphy_U1352B.csv\n",
       "4       768  317_Lithostratigraphy_U1352C.csv"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "select count(*) as db_count, data_source_notes as file\n",
    "from  samples\n",
    "where samples.data_source_type = 'lithology csv'\n",
    "group by data_source_notes;\n",
    "\"\"\"\n",
    "db_df = pd.read_sql(sql, db.conn)\n",
    "db_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>original_count</th>\n",
       "      <th>db_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>361_macroscopic_U1474D.csv</td>\n",
       "      <td>151</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>323 Core Description Template_U1341A.csv</td>\n",
       "      <td>654</td>\n",
       "      <td>611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>361_macroscopic_U1479C.csv</td>\n",
       "      <td>254</td>\n",
       "      <td>254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>340_sediment_U1393A.csv</td>\n",
       "      <td>20</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>339_sediment_U1386A.csv</td>\n",
       "      <td>592</td>\n",
       "      <td>592.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       file  original_count  db_count\n",
       "0                361_macroscopic_U1474D.csv             151     151.0\n",
       "1  323 Core Description Template_U1341A.csv             654     611.0\n",
       "2                361_macroscopic_U1479C.csv             254     254.0\n",
       "3                   340_sediment_U1393A.csv              20      20.0\n",
       "4                   339_sediment_U1386A.csv             592     592.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_db_df = pd.merge(df, db_df, on=\"file\", how=\"outer\")\n",
    "merged_db_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(518, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_db_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>original_count</th>\n",
       "      <th>db_count</th>\n",
       "      <th>compare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>361_macroscopic_U1474D.csv</td>\n",
       "      <td>151</td>\n",
       "      <td>151.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>323 Core Description Template_U1341A.csv</td>\n",
       "      <td>654</td>\n",
       "      <td>611.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>361_macroscopic_U1479C.csv</td>\n",
       "      <td>254</td>\n",
       "      <td>254.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>340_sediment_U1393A.csv</td>\n",
       "      <td>20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>339_sediment_U1386A.csv</td>\n",
       "      <td>592</td>\n",
       "      <td>592.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       file  original_count  db_count  compare\n",
       "0                361_macroscopic_U1474D.csv             151     151.0     True\n",
       "1  323 Core Description Template_U1341A.csv             654     611.0    False\n",
       "2                361_macroscopic_U1479C.csv             254     254.0     True\n",
       "3                   340_sediment_U1393A.csv              20      20.0     True\n",
       "4                   339_sediment_U1386A.csv             592     592.0     True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_db_df['compare'] = merged_db_df['original_count'] == merged_db_df['db_count']\n",
    "merged_db_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>original_count</th>\n",
       "      <th>db_count</th>\n",
       "      <th>compare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>323 Core Description Template_U1341A.csv</td>\n",
       "      <td>654</td>\n",
       "      <td>611.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>320 Core Description_U1332A.csv</td>\n",
       "      <td>208</td>\n",
       "      <td>207.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>334_sediment_U1378B.csv</td>\n",
       "      <td>756</td>\n",
       "      <td>744.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>323 Core Description Template_U1340D.csv</td>\n",
       "      <td>67</td>\n",
       "      <td>65.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>323 Core Description Template_U1341B.csv</td>\n",
       "      <td>893</td>\n",
       "      <td>845.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>323 Core Description Template_U1343E.csv</td>\n",
       "      <td>783</td>\n",
       "      <td>779.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>320 Core Description_U1331A.csv</td>\n",
       "      <td>247</td>\n",
       "      <td>238.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>356-U1464B_macroscopic.csv</td>\n",
       "      <td>320</td>\n",
       "      <td>319.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>374_U1524A_macroscopic.csv</td>\n",
       "      <td>725</td>\n",
       "      <td>710.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>323 Core Description Template_U1343D.csv</td>\n",
       "      <td>17</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         file  original_count  db_count  \\\n",
       "1    323 Core Description Template_U1341A.csv             654     611.0   \n",
       "5             320 Core Description_U1332A.csv             208     207.0   \n",
       "13                    334_sediment_U1378B.csv             756     744.0   \n",
       "26   323 Core Description Template_U1340D.csv              67      65.0   \n",
       "29   323 Core Description Template_U1341B.csv             893     845.0   \n",
       "..                                        ...             ...       ...   \n",
       "486  323 Core Description Template_U1343E.csv             783     779.0   \n",
       "488           320 Core Description_U1331A.csv             247     238.0   \n",
       "499                356-U1464B_macroscopic.csv             320     319.0   \n",
       "510                374_U1524A_macroscopic.csv             725     710.0   \n",
       "514  323 Core Description Template_U1343D.csv              17      16.0   \n",
       "\n",
       "     compare  \n",
       "1      False  \n",
       "5      False  \n",
       "13     False  \n",
       "26     False  \n",
       "29     False  \n",
       "..       ...  \n",
       "486    False  \n",
       "488    False  \n",
       "499    False  \n",
       "510    False  \n",
       "514    False  \n",
       "\n",
       "[73 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_db_df[merged_db_df['compare'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare sample name with exp...extra columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_temp_sample_name(df):\n",
    "    \"\"\"Uses Exp...A/W columns to create a name for a sample\"\"\"\n",
    "    names = {\"Exp\", \"Site\", \"Hole\", \"Core\", \"Type\", \"Section\", \"A/W\"}\n",
    "    if names.issubset(df.columns):\n",
    "        df[\"temp_sample\"] = df.apply(\n",
    "            lambda row: create_sample_name_for_row(row, df.columns), axis=1\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"File does not have the expected columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "\n",
    "for directory in LIMS_paths:\n",
    "    raw_csvs = glob.glob(f\"{directory}/*.csv\")\n",
    "    \n",
    "    for path in raw_csvs:\n",
    "        content = pd.read_csv(path, dtype=str)\n",
    "\n",
    "        create_temp_sample_name(content)\n",
    "        content['invalid_sample_name'] = content['Sample'] != content['temp_sample']\n",
    "\n",
    "        invalid_count = sum(content['invalid_sample_name'])\n",
    "        if invalid_count > 0:\n",
    "            files.append({'path': path, 'invalid_sample_name':invalid_count })\n",
    "            base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'path': 'cleaned_data/Lithology_CSV/339_sediment_U1390A.csv',\n",
       "  'invalid_sample_name': 581},\n",
       " {'path': 'cleaned_data/Lithology_CSV/334_sediment_U1378B.csv',\n",
       "  'invalid_sample_name': 756},\n",
       " {'path': 'cleaned_data/Lithology_CSV/349_macroscopic_U1431E.csv',\n",
       "  'invalid_sample_name': 1355},\n",
       " {'path': 'cleaned_data/Lithology_CSV/320 Core Description_U1332C.csv',\n",
       "  'invalid_sample_name': 226},\n",
       " {'path': 'cleaned_data/Lithology_CSV/339_sediment_U1386C.csv',\n",
       "  'invalid_sample_name': 169},\n",
       " {'path': 'cleaned_data/Lithology_CSV/344_sediment_U1413B.csv',\n",
       "  'invalid_sample_name': 2},\n",
       " {'path': 'cleaned_data/Lithology_CSV/340_sediment_U1399A.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Lithology_CSV/340_sediment_U1395B.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Lithology_CSV/340_sediment_U1399B.csv',\n",
       "  'invalid_sample_name': 670},\n",
       " {'path': 'cleaned_data/Lithology_CSV/351_macroscopic_U1438D.csv',\n",
       "  'invalid_sample_name': 11},\n",
       " {'path': 'cleaned_data/Lithology_CSV/329_sediment_U1369D.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Lithology_CSV/342_sediment_U1402B.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Lithology_CSV/351_macroscopic_U1438B.csv',\n",
       "  'invalid_sample_name': 3},\n",
       " {'path': 'cleaned_data/Lithology_CSV/329_sediment_U1368B.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Lithology_CSV/340_sediment_U1394B.csv',\n",
       "  'invalid_sample_name': 35},\n",
       " {'path': 'cleaned_data/Lithology_CSV/340_sediment_U1398A.csv',\n",
       "  'invalid_sample_name': 2},\n",
       " {'path': 'cleaned_data/Lithology_CSV/329_sediment_U1366E.csv',\n",
       "  'invalid_sample_name': 3},\n",
       " {'path': 'cleaned_data/Lithology_CSV/340_sediment_U1397B.csv',\n",
       "  'invalid_sample_name': 661},\n",
       " {'path': 'cleaned_data/Lithology_CSV/340_sediment_U1396A.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Lithology_CSV/340_sediment_U1400B.csv',\n",
       "  'invalid_sample_name': 953},\n",
       " {'path': 'cleaned_data/Lithology_CSV/340_sediment_U1396C.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Lithology_CSV/340_sediment_U1400C.csv',\n",
       "  'invalid_sample_name': 5},\n",
       " {'path': 'cleaned_data/Lithology_CSV/341_core_description_U1420A.csv',\n",
       "  'invalid_sample_name': 337},\n",
       " {'path': 'cleaned_data/Lithology_CSV/350_macroscopic_U1436B.csv',\n",
       "  'invalid_sample_name': 364},\n",
       " {'path': 'cleaned_data/Lithology_CSV/339_sediment_U1389E.csv',\n",
       "  'invalid_sample_name': 741},\n",
       " {'path': 'cleaned_data/Lithology_CSV/342_sediment_U1410A.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Lithology_CSV/317_Lithostratigraphy_U1353A.csv',\n",
       "  'invalid_sample_name': 6},\n",
       " {'path': 'cleaned_data/Lithology_CSV/339_sediment_U1385B.csv',\n",
       "  'invalid_sample_name': 159},\n",
       " {'path': 'cleaned_data/Lithology_CSV/330_sediment_U1376A.csv',\n",
       "  'invalid_sample_name': 3},\n",
       " {'path': 'cleaned_data/Lithology_CSV/342_sediment_U1406A.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Lithology_CSV/323 Core Description Template_U1343E.csv',\n",
       "  'invalid_sample_name': 783},\n",
       " {'path': 'cleaned_data/Lithology_CSV/339_sediment_U1385A.csv',\n",
       "  'invalid_sample_name': 215},\n",
       " {'path': 'cleaned_data/Lithology_CSV/341_core_description_U1421A.csv',\n",
       "  'invalid_sample_name': 32},\n",
       " {'path': 'cleaned_data/Micropal_CSV_1/320_U1332A_Nannofossils.csv',\n",
       "  'invalid_sample_name': 4},\n",
       " {'path': 'cleaned_data/Micropal_CSV_1/318_U1360A_Dinoflagellates.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_1/318_U1360A_Palynology.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_1/318_U1356A_Diatoms_1.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_1/318_U1356A_Diatoms_2.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_1/318_U1359A_Diatoms_1.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/356-U1464C_benthic_forams.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/350_U1437E_planktic_forams.csv',\n",
       "  'invalid_sample_name': 26},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/350_U1437D_planktic_forams.csv',\n",
       "  'invalid_sample_name': 2},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/350_U1437B_nannofossils.csv',\n",
       "  'invalid_sample_name': 4},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/349_U1435A_nannofossils.csv',\n",
       "  'invalid_sample_name': 3},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/351_U1438A_radiolarians.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/350_U1436B_nannofossils.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/359-U1465A_planktic_forams.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/350_U1437B_planktic_forams.csv',\n",
       "  'invalid_sample_name': 2},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/349_U1434A_nannofossils.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/362_U1481A_planktic_forams.csv',\n",
       "  'invalid_sample_name': 2},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/356-U1459C_nannofossils.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/349_U1431D_nannofossils.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/350_U1436C_nannofossils.csv',\n",
       "  'invalid_sample_name': 3},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/362_U1481A_radiolarians.csv',\n",
       "  'invalid_sample_name': 2},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/368_U1504A_nannofossils.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/368_U1504A_planktic_forams.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/350_U1436A_planktic_forams.csv',\n",
       "  'invalid_sample_name': 7},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/350_U1436A_benthic_forams.csv',\n",
       "  'invalid_sample_name': 6},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/350_U1437B_benthic_forams.csv',\n",
       "  'invalid_sample_name': 2},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/350_U1437D_nannofossils.csv',\n",
       "  'invalid_sample_name': 5},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/346_U1427A_nannofossils.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/359-U1466A_planktic_forams.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/354_U1450A_nannofossils.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/350_U1437D_benthic_forams.csv',\n",
       "  'invalid_sample_name': 3},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/356-U1464C_planktic_forams.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/369_U1516C_nannofossils.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/350_U1437E_nannofossils.csv',\n",
       "  'invalid_sample_name': 3},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/359-U1465A_benthic_forams.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/354_U1451A_nannofossils.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/359-U1466A_benthic_forams.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_2/346_U1430A_diatoms.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/339_benthic_forams_U1388B_5.csv',\n",
       "  'invalid_sample_name': 2},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/323_Radiolarians_U1341A.csv',\n",
       "  'invalid_sample_name': 10},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/339_benthic_forams_U1388B_4.csv',\n",
       "  'invalid_sample_name': 2},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/339_benthic_forams_U1388B_6.csv',\n",
       "  'invalid_sample_name': 2},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/323_Radiolarians_U1341B.csv',\n",
       "  'invalid_sample_name': 5},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/340_benthic_forams_U1393A.csv',\n",
       "  'invalid_sample_name': 6},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/339_benthic_forams_U1388B_3.csv',\n",
       "  'invalid_sample_name': 2},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/341_radiolarians_U1418F.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/323_Radiolarians_U1340B.csv',\n",
       "  'invalid_sample_name': 5},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/339_benthic_forams_U1388B_2.csv',\n",
       "  'invalid_sample_name': 2},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/339_benthic_forams_U1386B_5.csv',\n",
       "  'invalid_sample_name': 2},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/341_diatoms_U1418F.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/323_Radiolarians_U1340A.csv',\n",
       "  'invalid_sample_name': 10},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/342_nannofossils_U1410A_1.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/323_U1341A_planktic_forams.csv',\n",
       "  'invalid_sample_name': 10},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/340_benthic_forams_U1395A.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/323_U1339D_planktic_forams.csv',\n",
       "  'invalid_sample_name': 14},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/339_nannofossils_U1385A.csv',\n",
       "  'invalid_sample_name': 4},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/341_planktic_forams_U1417D.csv',\n",
       "  'invalid_sample_name': 15},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/340_benthic_forams_U1398A.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/323_U1340A_planktic_forams.csv',\n",
       "  'invalid_sample_name': 10},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/341_benthic_forams_U1417B.csv',\n",
       "  'invalid_sample_name': 6},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/340_benthic_forams_U1398B.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/341_planktic_forams_U1417C.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/323_U1340B_planktic_forams.csv',\n",
       "  'invalid_sample_name': 6},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/341_planktic_forams_U1417B.csv',\n",
       "  'invalid_sample_name': 4},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/340_benthic_forams_U1397A.csv',\n",
       "  'invalid_sample_name': 4},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/340_benthic_forams_U1397B.csv',\n",
       "  'invalid_sample_name': 14},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/340_benthic_forams_U1400C.csv',\n",
       "  'invalid_sample_name': 27},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/339_nannofossils_U1386A.csv',\n",
       "  'invalid_sample_name': 9},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/340_benthic_forams_U1400B.csv',\n",
       "  'invalid_sample_name': 2},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/330_planktic_forams_U1373A.csv',\n",
       "  'invalid_sample_name': 2},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/323_U1342A_planktic_forams.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/341_diatoms_U1417E.csv',\n",
       "  'invalid_sample_name': 5},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/341_diatoms_U1417D.csv',\n",
       "  'invalid_sample_name': 186},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/323_Radiolarians_U1342D.csv',\n",
       "  'invalid_sample_name': 5},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/323_Nannofossils_U1341B.csv',\n",
       "  'invalid_sample_name': 5},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/323_U1342C_planktic_forams.csv',\n",
       "  'invalid_sample_name': 6},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/339_planktic_forams_U1389B.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/323_U1342B_planktic_forams.csv',\n",
       "  'invalid_sample_name': 4},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/341_radiolarians_U1417D.csv',\n",
       "  'invalid_sample_name': 64},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/339_benthic_forams_U1387C_3.csv',\n",
       "  'invalid_sample_name': 6},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/323_U1342D_planktic_forams.csv',\n",
       "  'invalid_sample_name': 5},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/323_Radiolarians_U1342C.csv',\n",
       "  'invalid_sample_name': 6},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/341_diatoms_U1417C.csv',\n",
       "  'invalid_sample_name': 75},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/341_diatoms_U1417B.csv',\n",
       "  'invalid_sample_name': 104},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/323_Radiolarians_U1342B.csv',\n",
       "  'invalid_sample_name': 4},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/323_U1340A_Nannofossils.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/341_radiolarians_U1417A.csv',\n",
       "  'invalid_sample_name': 2},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/339_benthic_forams_U1387C_6.csv',\n",
       "  'invalid_sample_name': 7},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/323_Nannofossils_U1340B.csv',\n",
       "  'invalid_sample_name': 2},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/342_nannofossils_U1403B_1.csv',\n",
       "  'invalid_sample_name': 11},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/341_radiolarians_U1417C.csv',\n",
       "  'invalid_sample_name': 4},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/341_diatoms_U1417A.csv',\n",
       "  'invalid_sample_name': 43},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/323_Radiolarians_U1342A.csv',\n",
       "  'invalid_sample_name': 1},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/341_radiolarians_U1417B.csv',\n",
       "  'invalid_sample_name': 16},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/339_planktic_forams_U1389E.csv',\n",
       "  'invalid_sample_name': 61},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/339_benthic_forams_U1387C_5.csv',\n",
       "  'invalid_sample_name': 8},\n",
       " {'path': 'cleaned_data/Micropal_CSV_3/342_nannofossils_U1403B_2.csv',\n",
       "  'invalid_sample_name': 13},\n",
       " {'path': 'cleaned_data/Micropal_CSV_revised/363-U1482A-nannofossils_revised.csv',\n",
       "  'invalid_sample_name': 1}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## duplicate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "files = set()\n",
    "\n",
    "for directory in LIMS_paleo_paths:\n",
    "    raw_csvs = glob.glob(f\"{directory}/*.csv\")\n",
    "    for path in raw_csvs:\n",
    "        cols = ['Sample', 'Top [cm]', 'Top Depth [m]', 'Bottom [cm]', 'Bottom Depth [m]',\n",
    "#                'Zone name', 'Zone name (short)',\n",
    "               'Extra Sample ID Data']\n",
    "        df = pd.read_csv(path, usecols = cols)\n",
    "        new_df = df[df.duplicated()]\n",
    "        for index, row in new_df.iterrows():\n",
    "            data.append({'sample': row['Sample'], 'path': path})\n",
    "            files.add(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(data)\n",
    "new_df.to_csv('tmp/csvs_with_duplicate_sample_names.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gather problematic files for PI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_paths(metadata_path, output_base_path):\n",
    "    df = pd.read_csv(metadata_path)\n",
    "    df['raw_data_path'] = ''\n",
    "    raw_data_index = df.columns.get_loc('raw_data_path')\n",
    "    df['output_path'] = ''\n",
    "    output_index = df.columns.get_loc('output_path')\n",
    "    df['relative_path'] = ''\n",
    "    relative_index = df.columns.get_loc('relative_path')\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        parts = row['path'].split('/')\n",
    "        original_directory = parts[1]\n",
    "        filename = parts[2]\n",
    "\n",
    "        if original_directory == 'Micropal_CSV_1':\n",
    "            directory = 'DESC Micropal CSV 1'\n",
    "        elif original_directory == 'Micropal_CSV_2':\n",
    "            directory = 'DESC Micropal CSV 2'\n",
    "        elif original_directory == 'Micropal_CSV_3':\n",
    "            directory = 'DESC Micropal CSV 3'\n",
    "        elif original_directory == 'Micropal_CSV_revised':\n",
    "            directory = 'DESC Micropal CSV revised'\n",
    "        else:\n",
    "            directory = 'DESC-Lithology-CSV'\n",
    "            \n",
    "        \n",
    "        df.iloc[index, raw_data_index]  = f'raw_data/{directory}/{filename}'\n",
    "        df.iloc[index, output_index]  = f'{output_base_path}/{directory}/{filename}'\n",
    "        df.iloc[index, relative_index]  = f'{directory}/{filename}'\n",
    "\n",
    "\n",
    "    df.to_csv(metadata_path, index=False)\n",
    "    \n",
    "def copy_files(metadata_path):\n",
    "    df = pd.read_csv(metadata_path)\n",
    "    \n",
    "    directories = [re.sub('/[A-Za-z0-9\\-_ ]+\\.csv$', '', path)for path in list(df['output_path'])]\n",
    "    unique_directories = set(directories)\n",
    "    for directory in unique_directories:\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    for index, row in df.iterrows():\n",
    "        shutil.copy(row['raw_data_path'], row['output_path'])\n",
    "        \n",
    "\n",
    "def create_sample_name(df):\n",
    "    \"\"\"Uses Exp...A/W columns to create a name for a sample\"\"\"\n",
    "    names = {\"Exp\", \"Site\", \"Hole\", \"Core\", \"Type\", \"Section\", \"A/W\"}\n",
    "    if names.issubset(df.columns):\n",
    "        df[\"Temp_Sample\"] = df.apply(\n",
    "            lambda row: create_sample_name_for_row(row, df.columns), axis=1\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"File does not have the expected columns.\")\n",
    "        \n",
    "\n",
    "def process_files(metadata_path):\n",
    "    df = pd.read_csv(metadata_path)\n",
    "    for index, row in df.iterrows():\n",
    "        content = pd.read_csv(row['output_path'], dtype=str)\n",
    "        \n",
    "        if \"Sample\" in content.columns:\n",
    "            pass\n",
    "        elif \"Label ID\" in content.columns:\n",
    "            pass\n",
    "        else:\n",
    "            content['Temp_Sample'] = ''\n",
    "            create_sample_name(content)\n",
    "            \n",
    "        content = csv_cleanup(content, row['output_path'])\n",
    "        content.to_csv(row['output_path'], index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = 'tmp/csvs_with_duplicate_sample_names.csv'\n",
    "output_base_path = 'tmp/duplicate_samples'\n",
    "\n",
    "add_paths(metadata_path, output_base_path)\n",
    "copy_files(metadata_path)\n",
    "process_files(metadata_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = 'tmp/csvs_with_missing_samples.csv'\n",
    "output_base_path = 'tmp/missing_samples'\n",
    "\n",
    "add_paths(metadata_path, output_base_path)\n",
    "copy_files(metadata_path)\n",
    "process_files(metadata_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find all taxon groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxon_groups = set()\n",
    "\n",
    "for directory in LIMS_paleo_paths:\n",
    "    raw_csvs = glob.glob(f\"{directory}/*.csv\")\n",
    "    for path in raw_csvs:\n",
    "        \n",
    "        parts = path.split('/')\n",
    "        filename = parts[2]\n",
    "        partial_path = '/'.join(parts[1:3])\n",
    "        taxon_group = extract_taxon_group_from_filename(filename)\n",
    "        taxon_groups.add(taxon_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'benthic_forams',\n",
       " 'bolboformids',\n",
       " 'chrysophyte_cysts',\n",
       " 'diatoms',\n",
       " 'dinoflagellates',\n",
       " 'ebridians',\n",
       " 'nannofossils',\n",
       " 'ostracods',\n",
       " 'palynology',\n",
       " 'planktic_forams',\n",
       " 'radiolarians',\n",
       " 'silicoflagellates'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxon_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1116, 14)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxa_df = pd.read_csv(taxa_meta)\n",
    "taxa_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['file', 'path', 'taxon_group', 'empty_rows_columns',\n",
       "       'remove_identical_rows', 'remove_identical_columns',\n",
       "       'standardize_headers', 'add_expedition_aw_cols', 'add_sample_column',\n",
       "       'add_missing_cols', 'clean_up_taxa_values',\n",
       "       'clean_up_taxa_metadata_values', 'update_zones', 'add_missing_zone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxa_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/53550988/count-occurrences-of-false-or-true-in-a-column-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "614"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxa_df.add_expedition_aw_cols.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxa_df.add_sample_column.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
