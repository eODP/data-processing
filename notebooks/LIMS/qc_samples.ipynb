{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from config import CLEAN_DATA_DIR, OUTPUT_DIR, RAW_DATA_DIR\n",
    "import db as db\n",
    "\n",
    "\n",
    "from scripts.normalize_data import (\n",
    "    csv_cleanup,\n",
    "    update_metadata,\n",
    "    get_taxonomy_columns,\n",
    ")\n",
    "\n",
    "from scripts.shared_utils import (\n",
    "    log_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../../output/cleaned_data')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLEAN_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_paths = [\n",
    "    CLEAN_DATA_DIR /'LIMS/Micropal_CSV_1', \n",
    "    CLEAN_DATA_DIR /'LIMS/Micropal_CSV_2', \n",
    "    CLEAN_DATA_DIR /'LIMS/Micropal_CSV_3', \n",
    "    CLEAN_DATA_DIR /'LIMS/Micropal_CSV_4', \n",
    "    CLEAN_DATA_DIR /'LIMS/Micropal_CSV_revised', \n",
    "]\n",
    "\n",
    "date = '2022-04-28'\n",
    "\n",
    "\n",
    "taxa_list_file = OUTPUT_DIR/'taxa'/'LIMS'/f\"taxa_list_{date}.csv\"\n",
    "taxa_crosswalk_list_file = OUTPUT_DIR/'taxa'/'LIMS'/f\"taxa_crosswalk_{date}.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check if all files are imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LIMS/Micropal_CSV_1/363-U1482A-Benthic_Forams.csv',\n",
       " 'LIMS/Micropal_CSV_1/320_U1336A_Nannofossils_2.csv',\n",
       " 'LIMS/Micropal_CSV_1/375_U1518F_planktic_forams.csv']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = []\n",
    "\n",
    "for clean_data_path in clean_data_paths:\n",
    "    raw_csvs = glob.glob(f\"{clean_data_path}/*.csv\")\n",
    "    for csv in raw_csvs:\n",
    "        files.append(csv.split('cleaned_data/')[1])\n",
    "\n",
    "files[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1253"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LIMS/Micropal_CSV_3/339_nannofossils_U1387C.csv',\n",
       " 'LIMS/Micropal_CSV_4/317_U1353_planktic_forams.csv',\n",
       " 'LIMS/Micropal_CSV_3/341_diatoms_U1417E.csv']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "select distinct(data_source_notes) as file\n",
    "from samples \n",
    "where data_source_type = 'micropal csv';\n",
    "\"\"\"\n",
    "\n",
    "db_files = []\n",
    "rows = db.fetch_all(sql)\n",
    "for row in rows:\n",
    "    db_files.append(row['file'])\n",
    "    \n",
    "db_files[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1253"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(db_files) - set(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check if taxa column for all files are imported\n",
    "\n",
    "get files with no samples_taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LIMS/Micropal_CSV_2/371_U1511B_benthic_forams.csv',\n",
       " 'LIMS/Micropal_CSV_2/371_U1511A_benthic_forams.csv',\n",
       " 'LIMS/Micropal_CSV_2/346_U1423C_nannofossils.csv']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "select distinct(data_source_notes) from samples where data_source_type = 'micropal csv'\n",
    "except\n",
    "select distinct(data_source_notes) from samples_taxa;\n",
    "\"\"\"\n",
    "\n",
    "db_files = []\n",
    "rows = db.fetch_all(sql)\n",
    "for row in rows:\n",
    "    db_files.append(row['data_source_notes'])\n",
    "    \n",
    "db_files[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get all verbatim_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Valkyria pukapuka', 'Spirotextularia fistulosa', 'Monalysidium spp.']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "select distinct(verbatim_name)\n",
    "from taxa_crosswalk;\n",
    "\"\"\"\n",
    "taxa = []\n",
    "rows = db.fetch_all(sql)\n",
    "for row in rows:\n",
    "    taxa.append(row['verbatim_name'])\n",
    "    \n",
    "taxa[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print file name if there are taxa columns with abundance values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all files ok\n"
     ]
    }
   ],
   "source": [
    "errors = False \n",
    "\n",
    "for file in db_files:\n",
    "    path = CLEAN_DATA_DIR/file\n",
    "    df = pd.read_csv(path)\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "    \n",
    "    if len(set(df.columns).intersection(set(taxa))) > 0:\n",
    "        print(path)\n",
    "        errors = True \n",
    "        \n",
    "if not errors:\n",
    "    print('all files ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for duplicate sample names in all mircopal files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[]\n",
    "target_columns = [\n",
    "    'Sample', \n",
    "    'Top [cm]', \n",
    "    'Bottom [cm]', \n",
    "    'Top Depth [m]', \n",
    "    'Bottom Depth [m]'\n",
    "]\n",
    "for clean_data_path in clean_data_paths:\n",
    "    raw_csvs = glob.glob(f\"{clean_data_path}/*.csv\")\n",
    "\n",
    "    for path in raw_csvs:\n",
    "        content = pd.read_csv(path)\n",
    "        \n",
    "        new_df = content[content.duplicated(subset=['Sample'])]\n",
    "        for index, row in new_df.iterrows():\n",
    "            data.append({'sample': row['Sample'],  'path': path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(636, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame(data)\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>363-U1487A-4H-CC-PAL-NANNO</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_1/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>363-U1487A-5H-CC-PAL-NANNO</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_1/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>363-U1483A-1H-1-A 0/0-NANNO</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_1/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>363-U1483A-9H-6-W 50/50-NANNO</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_1/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>363-U1483A-11H-2-W 50/50-NANNO</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_1/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>323-U1345A-1H-1-nan</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_4/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>323-U1345A-1H-2-nan</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_4/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>323-U1345A-1H-2-nan</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_4/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>323-U1345A-2H-1-nan</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_4/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>323-U1345A-2H-1-nan</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_4/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>636 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             sample  \\\n",
       "0        363-U1487A-4H-CC-PAL-NANNO   \n",
       "1        363-U1487A-5H-CC-PAL-NANNO   \n",
       "2       363-U1483A-1H-1-A 0/0-NANNO   \n",
       "3     363-U1483A-9H-6-W 50/50-NANNO   \n",
       "4    363-U1483A-11H-2-W 50/50-NANNO   \n",
       "..                              ...   \n",
       "631             323-U1345A-1H-1-nan   \n",
       "632             323-U1345A-1H-2-nan   \n",
       "633             323-U1345A-1H-2-nan   \n",
       "634             323-U1345A-2H-1-nan   \n",
       "635             323-U1345A-2H-1-nan   \n",
       "\n",
       "                                                  path  \n",
       "0    ../../output/cleaned_data/LIMS/Micropal_CSV_1/...  \n",
       "1    ../../output/cleaned_data/LIMS/Micropal_CSV_1/...  \n",
       "2    ../../output/cleaned_data/LIMS/Micropal_CSV_1/...  \n",
       "3    ../../output/cleaned_data/LIMS/Micropal_CSV_1/...  \n",
       "4    ../../output/cleaned_data/LIMS/Micropal_CSV_1/...  \n",
       "..                                                 ...  \n",
       "631  ../../output/cleaned_data/LIMS/Micropal_CSV_4/...  \n",
       "632  ../../output/cleaned_data/LIMS/Micropal_CSV_4/...  \n",
       "633  ../../output/cleaned_data/LIMS/Micropal_CSV_4/...  \n",
       "634  ../../output/cleaned_data/LIMS/Micropal_CSV_4/...  \n",
       "635  ../../output/cleaned_data/LIMS/Micropal_CSV_4/...  \n",
       "\n",
       "[636 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df.to_csv('../../output/tmp/dup_sample_names.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import all samples into db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clean_data_path in clean_data_paths:\n",
    "    raw_csvs = glob.glob(f\"{clean_data_path}/*.csv\")\n",
    "\n",
    "    for path in raw_csvs:\n",
    "        filename = path.split('/')[2]\n",
    "        content = pd.read_csv(path)\n",
    "\n",
    "        for index, row in content.iterrows():\n",
    "             if type(row['Sample']) is str and (type(row['Top [cm]']) is int or type(row['Top [cm]']) is float):\n",
    "\n",
    "                 top =  0 if math.isnan(row['Top [cm]']) else row['Top [cm]']\n",
    "                 sample = row['Sample'].strip()\n",
    "                 sql = f\"INSERT INTO staging.samples (name,top,bottom,top_depth,bottom_depth, created_at, data_source_notes)  VALUES (\\'{sample}\\', {top} , {row['Bottom [cm]']} , {row['Top Depth [m]']} ,{row['Bottom Depth [m]']}, now(), \\'{filename}\\');\"\n",
    "                 # db.execute(sql);\n",
    "             else:\n",
    "                print(row['Sample'], row['Top [cm]'], row['Bottom [cm]'], row['Top Depth [m]'], row['Bottom Depth [m]'], path )\n",
    "\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
