{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from scripts.normalize_data import (\n",
    "    csv_cleanup,\n",
    "    update_metadata,\n",
    "    get_taxonomy_columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_paths = [\n",
    "    '../../output/cleaned_data/LIMS/Micropal_CSV_1', \n",
    "    '../../output/cleaned_data/LIMS/Micropal_CSV_2',\n",
    "    '../../output/cleaned_data/LIMS/Micropal_CSV_3',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>Top [cm]</th>\n",
       "      <th>Bottom [cm]</th>\n",
       "      <th>Top Depth [m]</th>\n",
       "      <th>Bottom Depth [m]</th>\n",
       "      <th>Zone name (short)</th>\n",
       "      <th>Zone name</th>\n",
       "      <th>Datum name</th>\n",
       "      <th>Preservation</th>\n",
       "      <th>Group Abundance</th>\n",
       "      <th>...</th>\n",
       "      <th>Shore File Links</th>\n",
       "      <th>File Data</th>\n",
       "      <th>Exp</th>\n",
       "      <th>Site</th>\n",
       "      <th>Hole</th>\n",
       "      <th>Core</th>\n",
       "      <th>Type</th>\n",
       "      <th>Section</th>\n",
       "      <th>A/W</th>\n",
       "      <th>eodp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Sample, Top [cm], Bottom [cm], Top Depth [m], Bottom Depth [m], Zone name (short), Zone name, Datum name, Preservation, Group Abundance,  Circodiscus (Porodiscus) circularis,  Cycladophora nakasekoi ,  Cycladophora sakaii,  Lithelius barbatus,  Lychnocanoma parallelipes, Acrobotrys tritubus, Acrosphaera spinosa, Actinomma delicatulum , Actinomma leptodermum, Antarctissa denticulata, Anthocyrtidium angulare, Anthocyrtidium ophirense, Bortyostrobus auritus/australis, Botryostrobus aquilonaris, Botryostrobus miralestense, Calocycletta costata, Calocycletta virginis, Ceratospyris borealis, Cycladophora bicornis, Cycladophora davisiana , Cyrtocapsella cornuta , Cyrtocapsella japonica , Cyrtocapsella tetrapera , Dendrospyris?, Diartus hughesi, Diartus petterssoni, Dictyocoryne ontongensis, Dictyocoryne profunda , Dictyophimus bullatus, Dictyophimus hirundo , Didymocyrtis antepenultima, Didymocyrtis avita, Didymocyrtis laticonus, Didymocyrtis mammifera, Didymocyrtis penultima, Didymocyrtis prismatica, Didymocyrtis tetrathalamus, Didymocyrtis tubaria, Didymocyrtis violina, Dorcadospyris alata, Dorcadospyris ateuchus, Dorcadospyris dentata, Dorcadospyris forcipata, Dorcadospyris simplex, Euchitonia furcata/elegans, Euchitonia triangulatum, Eucyrtidium asanoi, Eucyrtidium calvertense, Eucyrtidium diaphanes, Eucyrtidium inflatum, Eucyrtidium matuyamai , Giraffospyris angulata , Heliodiscus astericus, Hexacontium enthacanthus, Hymeniastrum euclidis , Lamprocyclas junonis , Lamprocyrtis hannai, Lamprocyrtis heteroporos, Lamprocyrtis neoheteroporos, Lamprocyrtis nigriniae, Larcopyle buetschlii, Liriospyris reticulata, Lithelius minor, Lithopera neotera, Lithopera renzae , Lithopera thornbergi, Lychnocanoma nipponica magnacornuta, Lychnocanoma sakaii , Octopyle/Tetrapyle Group, Phomostichoartus corbula, Phormostichoartus doliolum, Phormostichoartus fistula, Porodiscus (?) sp. B , Prunopyle antartica, Pterocanium praetextum, Pterocanium prismatium, Pterocanium sp., Pterocorys group, Pterocorys minythorax, Siphostichartus corona, Sphaeropyle langii, Sphaeropyle robusta , Spongaster berminghami, Spongaster pentas, Spongaster tetras, Spongopyle osculosa, Spongurus (?) sp., Spongurus cf. elliptica , Spongurus pylomaticus, Stichocorys armata, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 126 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../../output/cleaned_data/LIMS/Micropal_CSV_3/341_radiolarians_U1421A.csv'\n",
    "content = pd.read_csv(path)\n",
    "cols = list(set(content.columns) - {'eodp_id'})\n",
    "print(len(cols))\n",
    "\n",
    "if len(content[content.duplicated(subset=cols)]) > 0:\n",
    "    content.drop_duplicates(inplace=True, subset=cols)\n",
    "    print(len(cols))\n",
    "    \n",
    "content[content.duplicated(subset=cols)]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clean_data_path in clean_data_paths:\n",
    "    raw_csvs = glob.glob(f\"{clean_data_path}/*.csv\")\n",
    "\n",
    "    for index, path in enumerate(raw_csvs):\n",
    "        content = pd.read_csv(path, dtype=str)\n",
    "        cols = list(set(content.columns) - {'eodp_id'})\n",
    "        \n",
    "        if len(content[content.duplicated(subset=cols)]) > 0:\n",
    "            content.drop_duplicates(inplace=True, subset=cols)\n",
    "            content = csv_cleanup(content, path)\n",
    "            content.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for duplicate sample names in all mircopal files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[]\n",
    "target_columns = [\n",
    "    'Sample', \n",
    "    'Top [cm]', \n",
    "    'Bottom [cm]', \n",
    "    'Top Depth [m]', \n",
    "    'Bottom Depth [m]'\n",
    "]\n",
    "for clean_data_path in clean_data_paths:\n",
    "    raw_csvs = glob.glob(f\"{clean_data_path}/*.csv\")\n",
    "\n",
    "    for path in raw_csvs:\n",
    "        content = pd.read_csv(path)\n",
    "        \n",
    "        new_df = content[content.duplicated(subset=target_columns)]\n",
    "        for index, row in new_df.iterrows():\n",
    "            data.append({'sample': row['Sample'],  'path': path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(467, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame(data)\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>363-U1487A-4H-CC-PAL-NANNO</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_1/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>363-U1487A-5H-CC-PAL-NANNO</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_1/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>363-U1483A-1H-1-A 0/0-NANNO</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_1/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>363-U1483A-9H-6-W 50/50-NANNO</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_1/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>363-U1483A-11H-2-W 50/50-NANNO</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_1/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>321-U1337A-32X-4-W</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_3/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>321-U1337A-32X-4-W</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_3/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>342-U1409A-1H-CC-PAL</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_3/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>342-U1409A-2H-CC-PAL</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_3/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>341-U1417B-12H-CC-PAL</td>\n",
       "      <td>../../output/cleaned_data/LIMS/Micropal_CSV_3/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>467 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             sample  \\\n",
       "0        363-U1487A-4H-CC-PAL-NANNO   \n",
       "1        363-U1487A-5H-CC-PAL-NANNO   \n",
       "2       363-U1483A-1H-1-A 0/0-NANNO   \n",
       "3     363-U1483A-9H-6-W 50/50-NANNO   \n",
       "4    363-U1483A-11H-2-W 50/50-NANNO   \n",
       "..                              ...   \n",
       "462              321-U1337A-32X-4-W   \n",
       "463              321-U1337A-32X-4-W   \n",
       "464            342-U1409A-1H-CC-PAL   \n",
       "465            342-U1409A-2H-CC-PAL   \n",
       "466           341-U1417B-12H-CC-PAL   \n",
       "\n",
       "                                                  path  \n",
       "0    ../../output/cleaned_data/LIMS/Micropal_CSV_1/...  \n",
       "1    ../../output/cleaned_data/LIMS/Micropal_CSV_1/...  \n",
       "2    ../../output/cleaned_data/LIMS/Micropal_CSV_1/...  \n",
       "3    ../../output/cleaned_data/LIMS/Micropal_CSV_1/...  \n",
       "4    ../../output/cleaned_data/LIMS/Micropal_CSV_1/...  \n",
       "..                                                 ...  \n",
       "462  ../../output/cleaned_data/LIMS/Micropal_CSV_3/...  \n",
       "463  ../../output/cleaned_data/LIMS/Micropal_CSV_3/...  \n",
       "464  ../../output/cleaned_data/LIMS/Micropal_CSV_3/...  \n",
       "465  ../../output/cleaned_data/LIMS/Micropal_CSV_3/...  \n",
       "466  ../../output/cleaned_data/LIMS/Micropal_CSV_3/...  \n",
       "\n",
       "[467 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('../../output/tmp/dup_sample_names.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import all samples into db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect():\n",
    "    return psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"eodp_dev\",\n",
    "    user=\"wyk\",\n",
    "    password=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connect()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for clean_data_path in clean_data_paths:\n",
    "    raw_csvs = glob.glob(f\"{clean_data_path}/*.csv\")\n",
    "\n",
    "    for path in raw_csvs:\n",
    "        filename = path.split('/')[2]\n",
    "        content = pd.read_csv(path)\n",
    "\n",
    "        for index, row in content.iterrows():\n",
    "             if type(row['Sample']) is str and (type(row['Top [cm]']) is int or type(row['Top [cm]']) is float):\n",
    "\n",
    "                 top =  0 if math.isnan(row['Top [cm]']) else row['Top [cm]']\n",
    "                 sample = row['Sample'].strip()\n",
    "                 sql = f\"INSERT INTO staging.samples (name,top,bottom,top_depth,bottom_depth, created_at, data_source_notes)  VALUES (\\'{sample}\\', {top} , {row['Bottom [cm]']} , {row['Top Depth [m]']} ,{row['Bottom Depth [m]']}, now(), \\'{filename}\\');\"\n",
    "                 cursor.execute(sql);\n",
    "             else:\n",
    "                print(row['Sample'], row['Top [cm]'], row['Bottom [cm]'], row['Top Depth [m]'], row['Bottom Depth [m]'], path )\n",
    "\n",
    "# conn.commit()\n",
    "# conn.close()\n",
    "# print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check taxa file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "from config import CLEAN_DATA_DIR, OUTPUT_DIR, RAW_DATA_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2022-04-28'\n",
    "\n",
    "\n",
    "taxa_list_file = OUTPUT_DIR/'taxa'/'LIMS'/f\"taxa_list_{date}.csv\"\n",
    "taxa_crosswalk_list_file = OUTPUT_DIR/'taxa'/'LIMS'/f\"taxa_crosswalk_{date}.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4678, 2)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(taxa_list_file, usecols=['normalized_name', 'taxon_group'])\n",
    "df.shape\n",
    "# 4678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized_name</th>\n",
       "      <th>taxon_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [normalized_name, taxon_group]\n",
       "Index: []"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated(subset=['normalized_name', 'taxon_group'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5267, 4)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(taxa_crosswalk_list_file, usecols=['normalized_name', 'taxon_group', 'verbatim_name','eodp_id'])\n",
    "df2.shape\n",
    "# 5267"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized_name</th>\n",
       "      <th>taxon_group</th>\n",
       "      <th>verbatim_name</th>\n",
       "      <th>eodp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [normalized_name, taxon_group, verbatim_name, eodp_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2.duplicated(subset=['normalized_name', 'taxon_group', 'verbatim_name'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "\n",
    "DB_NAME = \"eodp_dev\"\n",
    "DB_USER = \"wyk\"\n",
    "DB_PASS = \"\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "conn = psycopg2.connect(database=DB_NAME,\n",
    "                        user=DB_USER,\n",
    "                        password=DB_PASS,\n",
    "                        host=DB_HOST,\n",
    "                        port=DB_PORT)\n",
    "\n",
    "cur = conn.cursor(cursor_factory=psycopg2.extras.DictCursor)\n",
    "cur.execute(\"\"\"\n",
    "SELECT * FROM taxa_crosswalk \n",
    "JOIN taxa on taxa.id = taxa_crosswalk.taxon_id \n",
    "\n",
    "\"\"\")\n",
    "rows = cur.fetchall()\n",
    "data = []\n",
    "for row in rows:\n",
    "    data.append({\n",
    "        'normalized_name': row['name'], \n",
    "        'taxon_group': row['taxon_group'],\n",
    "        'verbatim_name': row['original_name'],\n",
    "        'eodp_id': row['eodp_id']\n",
    "        \n",
    "    })\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5266"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized_name</th>\n",
       "      <th>taxon_group</th>\n",
       "      <th>verbatim_name</th>\n",
       "      <th>eodp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Euuvigerina miozea</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>Euuvigerina miozea (group) &gt;100 m</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Euuvigerina rodleyi</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>Euuvigerina rodleyi (group) &gt;50 m</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Foraminifera indet.</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>Others</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pleurostomellidae indet.</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>Pleurostomellids comment</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ostracoda indet.</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>Ostracoda spp.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            normalized_name     taxon_group  \\\n",
       "0        Euuvigerina miozea  benthic_forams   \n",
       "1       Euuvigerina rodleyi  benthic_forams   \n",
       "2       Foraminifera indet.  benthic_forams   \n",
       "3  Pleurostomellidae indet.  benthic_forams   \n",
       "4          Ostracoda indet.  benthic_forams   \n",
       "\n",
       "                       verbatim_name  eodp_id  \n",
       "0  Euuvigerina miozea (group) >100 m        0  \n",
       "1  Euuvigerina rodleyi (group) >50 m        1  \n",
       "2                             Others        2  \n",
       "3           Pleurostomellids comment        3  \n",
       "4                     Ostracoda spp.        4  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_df = pd.DataFrame(data)\n",
    "db_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3680}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df2['eodp_id']) - set (db_df['eodp_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(db_df['eodp_id']) - set (df2['eodp_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
