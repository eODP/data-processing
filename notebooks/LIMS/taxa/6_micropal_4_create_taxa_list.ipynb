{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Taxa list csv for micropal 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a csv containing taxa names for micropal 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "import glob\n",
    "import re\n",
    "import os.path\n",
    "import time\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scripts.normalize_data import (\n",
    "    csv_cleanup,\n",
    "    update_metadata,\n",
    "    get_taxonomy_columns,\n",
    "    clean_taxon_name,\n",
    "    extract_taxon_group_from_filename,\n",
    "    \n",
    ")\n",
    "from scripts.normalize_taxa import add_normalized_name_column, taxon_name_parser\n",
    "from config import CLEAN_DATA_DIR, OUTPUT_DIR, RAW_DATA_DIR\n",
    "\n",
    "from scripts.pbdb import get_parent_taxa, PBDB_TAXA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = CLEAN_DATA_DIR\n",
    "\n",
    "micropal_4 = CLEAN_DATA_DIR/'LIMS'/'Micropal_CSV_4'\n",
    "metadata_path = OUTPUT_DIR/'metadata'/'LIMS'/'Micropal_changes_4.csv'\n",
    "\n",
    "non_taxa_fields_path = OUTPUT_DIR/'taxa'/'non_taxa_fields.csv'\n",
    "\n",
    "LIMS_taxa_file = OUTPUT_DIR/'taxa'/'LIMS'/f\"taxa_crosswalk_2022-02-22.csv\"\n",
    "NOAA_taxa_file =  RAW_DATA_DIR/'PI_processed_files'/'NOAA_taxa_lists_taxa_list_2022-02-24.csv'\n",
    "\n",
    "date = '2022-02-24'\n",
    "taxa_file = OUTPUT_DIR/'taxa'/'draft'/'LIMS'/f\"micropal_4_taxa_{date}.csv\"\n",
    "genus_file= OUTPUT_DIR/'taxa'/'draft'/'LIMS'/f\"micropal_4_genus_{date}.csv\"\n",
    "taxa_pbdb_file = OUTPUT_DIR/'taxa'/'draft'/'LIMS'/f'micropal_4_taxa_pbdb_{date}.csv'\n",
    "genus_letter_file= OUTPUT_DIR/'taxa'/'draft'/'LIMS'/f\"micropal_4_genus_letter_{date}.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../../../output/cleaned_data/LIMS/Micropal_CSV_4/320_U1334_benthic_forams.csv'),\n",
       " PosixPath('../../../output/cleaned_data/LIMS/Micropal_CSV_4/361_U1479B_nannofossils.csv'),\n",
       " PosixPath('../../../output/cleaned_data/LIMS/Micropal_CSV_4/372_U1517C_planktic_forams.csv')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_csvs = []\n",
    "clean_csvs = clean_csvs + list(micropal_4.glob(\"*.csv\"))\n",
    "\n",
    "clean_csvs[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_df(df, row_count=5):\n",
    "    print(df.shape)\n",
    "    return df.head(row_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_path = CLEAN_DATA_DIR\n",
    "metadata_file = metadata_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create metadadta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get taxon groups from file names and normalize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'benthic_forams',\n",
       " 'diatoms',\n",
       " 'dinoflagellates',\n",
       " 'ebridians',\n",
       " 'nannofossils',\n",
       " 'ostracods',\n",
       " 'other',\n",
       " 'palynology',\n",
       " 'planktic_forams',\n",
       " 'radiolarians',\n",
       " 'rads',\n",
       " 'silicoflagellates'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_taxon_groups = set()\n",
    "\n",
    "for path in clean_csvs:\n",
    "    filename = path.name\n",
    "    group = extract_taxon_group_from_filename(filename)\n",
    "    raw_taxon_groups.add(group)\n",
    "    \n",
    "raw_taxon_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxon_groups = {\n",
    "'benthic_forams': 'benthic_forams',\n",
    " 'diatoms': 'diatoms',\n",
    " 'dinoflagellates': 'dinoflagellates',\n",
    " 'ebridians': 'ebridians',\n",
    " 'nannofossils': 'nannofossils',\n",
    " 'ostracods': 'ostracods',\n",
    " 'other': 'other',\n",
    " 'palynology': 'palynology',\n",
    " 'planktic_forams': 'planktic_forams',\n",
    " 'radiolarians': 'radiolarians',\n",
    " 'rads': 'radiolarians',\n",
    " 'silicoflagellates': 'silicoflagellates'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_taxon_groups = []\n",
    "filenames = []\n",
    "relative_paths = []\n",
    "\n",
    "\n",
    "for path in clean_csvs:\n",
    "    relative_path = path.relative_to(base_dir)\n",
    "    filename = path.name\n",
    "    raw_taxon_group = extract_taxon_group_from_filename(filename)\n",
    "    taxon_group = taxon_groups[raw_taxon_group]\n",
    "        \n",
    "    filenames.append(filename)\n",
    "    relative_paths.append(relative_path)\n",
    "    file_taxon_groups.append(taxon_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>path</th>\n",
       "      <th>taxon_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320_U1334_benthic_forams.csv</td>\n",
       "      <td>LIMS/Micropal_CSV_4/320_U1334_benthic_forams.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>361_U1479B_nannofossils.csv</td>\n",
       "      <td>LIMS/Micropal_CSV_4/361_U1479B_nannofossils.csv</td>\n",
       "      <td>nannofossils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>372_U1517C_planktic_forams.csv</td>\n",
       "      <td>LIMS/Micropal_CSV_4/372_U1517C_planktic_forams...</td>\n",
       "      <td>planktic_forams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>317_U1352_planktic_forams.csv</td>\n",
       "      <td>LIMS/Micropal_CSV_4/317_U1352_planktic_forams.csv</td>\n",
       "      <td>planktic_forams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>323_U1339_palynology.csv</td>\n",
       "      <td>LIMS/Micropal_CSV_4/323_U1339_palynology.csv</td>\n",
       "      <td>palynology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file  \\\n",
       "0    320_U1334_benthic_forams.csv   \n",
       "1     361_U1479B_nannofossils.csv   \n",
       "2  372_U1517C_planktic_forams.csv   \n",
       "3   317_U1352_planktic_forams.csv   \n",
       "4        323_U1339_palynology.csv   \n",
       "\n",
       "                                                path      taxon_group  \n",
       "0   LIMS/Micropal_CSV_4/320_U1334_benthic_forams.csv   benthic_forams  \n",
       "1    LIMS/Micropal_CSV_4/361_U1479B_nannofossils.csv     nannofossils  \n",
       "2  LIMS/Micropal_CSV_4/372_U1517C_planktic_forams...  planktic_forams  \n",
       "3  LIMS/Micropal_CSV_4/317_U1352_planktic_forams.csv  planktic_forams  \n",
       "4       LIMS/Micropal_CSV_4/323_U1339_palynology.csv       palynology  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\"file\": filenames,\n",
    "        \"path\": relative_paths,\n",
    "        \"taxon_group\": file_taxon_groups}\n",
    "\n",
    "metadata = pd.DataFrame(dict)\n",
    "log_df(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.to_csv(metadata_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a csv of all taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>path</th>\n",
       "      <th>taxon_group</th>\n",
       "      <th>change_file_encoding</th>\n",
       "      <th>remove_bad_characters</th>\n",
       "      <th>remove_empty_rows</th>\n",
       "      <th>remove_spaces</th>\n",
       "      <th>delete_duplicate_rows</th>\n",
       "      <th>delete_duplicate_columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320_U1334_benthic_forams.csv</td>\n",
       "      <td>LIMS/Micropal_CSV_4/320_U1334_benthic_forams.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>361_U1479B_nannofossils.csv</td>\n",
       "      <td>LIMS/Micropal_CSV_4/361_U1479B_nannofossils.csv</td>\n",
       "      <td>nannofossils</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>372_U1517C_planktic_forams.csv</td>\n",
       "      <td>LIMS/Micropal_CSV_4/372_U1517C_planktic_forams...</td>\n",
       "      <td>planktic_forams</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>317_U1352_planktic_forams.csv</td>\n",
       "      <td>LIMS/Micropal_CSV_4/317_U1352_planktic_forams.csv</td>\n",
       "      <td>planktic_forams</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>323_U1339_palynology.csv</td>\n",
       "      <td>LIMS/Micropal_CSV_4/323_U1339_palynology.csv</td>\n",
       "      <td>palynology</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file  \\\n",
       "0    320_U1334_benthic_forams.csv   \n",
       "1     361_U1479B_nannofossils.csv   \n",
       "2  372_U1517C_planktic_forams.csv   \n",
       "3   317_U1352_planktic_forams.csv   \n",
       "4        323_U1339_palynology.csv   \n",
       "\n",
       "                                                path      taxon_group  \\\n",
       "0   LIMS/Micropal_CSV_4/320_U1334_benthic_forams.csv   benthic_forams   \n",
       "1    LIMS/Micropal_CSV_4/361_U1479B_nannofossils.csv     nannofossils   \n",
       "2  LIMS/Micropal_CSV_4/372_U1517C_planktic_forams...  planktic_forams   \n",
       "3  LIMS/Micropal_CSV_4/317_U1352_planktic_forams.csv  planktic_forams   \n",
       "4       LIMS/Micropal_CSV_4/323_U1339_palynology.csv       palynology   \n",
       "\n",
       "   change_file_encoding  remove_bad_characters  remove_empty_rows  \\\n",
       "0                 False                  False              False   \n",
       "1                  True                   True              False   \n",
       "2                 False                  False              False   \n",
       "3                 False                  False              False   \n",
       "4                 False                  False              False   \n",
       "\n",
       "   remove_spaces  delete_duplicate_rows  delete_duplicate_columns  \n",
       "0           True                  False                     False  \n",
       "1           True                  False                     False  \n",
       "2           True                  False                     False  \n",
       "3           True                  False                     False  \n",
       "4           True                  False                     False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(metadata_path)\n",
    "log_df(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get all columns with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = set()\n",
    "for path in metadata['path']:\n",
    "    if '317_U1351_planktic_forams.csv' in str(path):\n",
    "        header = 1\n",
    "    else:\n",
    "        header = 0\n",
    "    df = pd.read_csv(clean_data_path/path, dtype=str, header=header)\n",
    "    df = csv_cleanup(df, clean_data_path/path)\n",
    "    df = df.dropna(how='all', axis='columns')\n",
    "    all_columns.update([col.strip() for col in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_cols = [col.strip() for col in all_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get procesessed LIMS taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_LIMS_taxa = set()\n",
    "\n",
    "existing_taxa_df = pd.read_csv(LIMS_taxa_file)\n",
    "for index, row in existing_taxa_df.iterrows():\n",
    "    existing_LIMS_taxa.add(row['verbatim_name'])\n",
    "    existing_LIMS_taxa.add(row['normalized_name'])\n",
    "\n",
    "len(existing_LIMS_taxa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get NOAA taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_NOAA_taxa = set()\n",
    "\n",
    "existing_taxa_df = pd.read_csv(NOAA_taxa_file)\n",
    "add_normalized_name_column(existing_taxa_df, include_descriptor=True, col_name=\"normalized_name_descriptor\")\n",
    "add_normalized_name_column(existing_taxa_df, include_descriptor=False, col_name=\"normalized_name\")\n",
    "\n",
    "for index, row in existing_taxa_df.iterrows():\n",
    "    existing_NOAA_taxa.add(row['verbatim_name'])\n",
    "    existing_NOAA_taxa.add(row['normalized_name_descriptor'])\n",
    "    existing_NOAA_taxa.add(row['normalized_name'])\n",
    "\n",
    "len(existing_NOAA_taxa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nontaxa = {\n",
    " 'Abundance',\n",
    " 'Abundance ',\n",
    " 'Abundance (%)',\n",
    " 'Abundances',\n",
    " 'Age',\n",
    " 'Age:',\n",
    " 'Benthic abundance',\n",
    " 'Biozone name',\n",
    " 'Biozone name (short)',\n",
    " 'Bottom (cm)',\n",
    " 'Bottom (m CSF-A)',\n",
    " 'Bottom CSF-A (m)',\n",
    " 'Bottom Depth (m)',\n",
    " 'Bottom Depth (m) CSF-A',\n",
    " 'Bottom Depth CSF-A (m)',\n",
    " 'Bottom Depth [CFS m]',\n",
    " 'Bottom Depth [m]',\n",
    " 'Bottom Offset (cm) on Parent Sample',\n",
    " 'Bottom [cm]',\n",
    " 'Bottom depth CSF-B (m)',\n",
    " 'Bottom depth CSF-B (m):',\n",
    " 'Bottom interval (cm)',\n",
    " 'COMMENTS',\n",
    " 'Comments',\n",
    " 'Core',\n",
    " 'Core Type',\n",
    " 'Core Type - Section',\n",
    " 'Core type',\n",
    " 'Core,    section',\n",
    " 'Core, Section',\n",
    " 'Core, Section, Interval',\n",
    " 'Core, section',\n",
    " 'Core, section, interval',\n",
    " 'Core, section, interval (cm)',\n",
    " 'Datum age average (Ma)',\n",
    " 'Datum name',\n",
    " 'Datum type',\n",
    " 'Depth (cm)',\n",
    " 'Depth (csf)',\n",
    " 'Depth (m) CSF-A',\n",
    " 'Depth CSF (m)',\n",
    " 'Depth CSF-A (m)',\n",
    " 'Depth Method',\n",
    " 'Depth bottom CSF-A (m)',\n",
    " 'Depth m (m csf)',\n",
    " 'Depth top CSF-A (m)',\n",
    " 'Exp',\n",
    " 'Expedition',\n",
    " 'Expedition ',\n",
    " 'Expedition, site, hole, core, section, interval (cm):',\n",
    " 'Foraminferal preservation',\n",
    " 'Foraminiferal abundance',\n",
    " 'Foraminiferal preservation',\n",
    " 'Group Abundance',\n",
    " 'Group abundance',\n",
    " 'Half',\n",
    " 'Hole',\n",
    " 'Hole, Core, Section',\n",
    " 'Hole.1',\n",
    " 'IRD',\n",
    " 'Interval (bottom)',\n",
    " 'Interval (top)',\n",
    " 'Interval Top (cm) on SHLF',\n",
    " 'Interval Bot (cm) on SHLF',   'Miscellaneous',\n",
    " 'Nannofossil Zone',\n",
    " 'Nannofossil abundance',\n",
    " 'Nannofossil comment',\n",
    " 'Oberservations',\n",
    " 'Observations',\n",
    " 'Original Bottom Depth (m)',\n",
    " 'Original Top Depth (m)',\n",
    " 'Other fossil material',\n",
    " 'Other observations',\n",
    " 'Other taxa',\n",
    " 'Preservation',\n",
    " 'Presevation',\n",
    " 'REMARKS',\n",
    " 'Remarks',\n",
    " 'Sample',\n",
    " 'Section',\n",
    " 'Section Half',\n",
    " 'Secton Half',\n",
    " 'Site',\n",
    " 'Top (cm)',\n",
    " 'Top (m CSF-A)',\n",
    " 'Top CSF-A (m)',\n",
    " 'Top Depth (CSF m)',\n",
    " 'Top Depth (m)',\n",
    " 'Top Depth (m) CSF-A',\n",
    " 'Top Depth CFS (m)',\n",
    " 'Top Depth CSF-A (m)',\n",
    " 'Top Depth [CFS m]',\n",
    " 'Top Depth [CSF m]',\n",
    " 'Top Depth [m]',\n",
    " 'Top Offset (cm) on Parent Sample',\n",
    " 'Top [cm]',\n",
    " 'Top depth CSF (m)',\n",
    " 'Top depth CSF-B (m)',\n",
    " 'Top depth CSF-B (m):',\n",
    " 'Top depth [CSF m]',\n",
    " 'Top interval (cm)',\n",
    " 'Total pollen',\n",
    " 'Total radiolarians',\n",
    " 'Type',\n",
    " 'Unnamed: 148',\n",
    " 'Unnamed: 21',\n",
    " 'Unnamed: 3',\n",
    " 'Unnamed: 61',\n",
    " 'Unnamed: 81',\n",
    " 'Zone',\n",
    " 'Zone name (short)',\n",
    " 'Zone/Subzone',\n",
    " 'bottom (cm)',\n",
    " 'bottom interval (cm)',\n",
    " 'comments',\n",
    " 'core, section',\n",
    " 'depth Bottom (m CSF-A)',\n",
    " 'depth Bottom (m)',\n",
    " 'depth Bottom CSF-A (m)',\n",
    " 'depth CSF-A',\n",
    " 'depth CSF-A (m)',\n",
    " 'depth CSF-A Bottom (m)',\n",
    " 'depth CSF-A Top (m)',\n",
    " 'depth Top (m CSF-A)',\n",
    " 'depth Top (m)',\n",
    " 'depth Top CSF-A (m)',\n",
    " 'interval (cm)',\n",
    " 'mean depth (mbsf)',\n",
    " 'preservation',\n",
    " 'section',\n",
    " 'top (cm)',\n",
    " 'top interval (cm)'\n",
    "}\n",
    "\n",
    "all_taxa_names = all_columns  - nontaxa\n",
    "taxa_names = all_taxa_names - existing_LIMS_taxa - existing_NOAA_taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_taxa_names), len(taxa_names), len(nontaxa))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a taxa list csv that contains all the taxon names and the associated taxon group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa_and_group = set()\n",
    "\n",
    "\n",
    "for index, row in metadata.iterrows():\n",
    "\n",
    "    file =  clean_data_path/row['path']\n",
    "    if '317_U1351_planktic_forams.csv' in str(path):\n",
    "        header = 1\n",
    "    else:\n",
    "        header = 0\n",
    "        \n",
    "    df = pd.read_csv(file, dtype=str, header=header, nrows=0)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col in taxa_names:\n",
    "            taxa_and_group.add(f'{col}|{row[\"taxon_group\"]}')\n",
    "\n",
    "\n",
    "len(taxa_and_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa_list = []\n",
    "\n",
    "for taxon in taxa_and_group:\n",
    "    if not pd.isna(taxon):\n",
    "        taxon_name, taxon_group = taxon.split('|')\n",
    "        \n",
    "        taxon_name_parts = taxon_name_parser(taxon_name)\n",
    "\n",
    "        data = { \n",
    "            'taxon_group': taxon_group, \n",
    "            'verbatim_name': taxon_name,\n",
    "        }\n",
    "        all_ranks =[\n",
    "            'genus modifier', 'genus name', 'species modifier', 'species name', \n",
    "            'subspecies modifier', 'subspecies name', 'non-taxa descriptor'\n",
    "        ]\n",
    "        for rank in all_ranks:            \n",
    "            if rank in taxon_name_parts:\n",
    "                data[rank] = taxon_name_parts[rank]\n",
    "\n",
    "        taxa_list.append(data)\n",
    "        \n",
    "len(taxa_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa_df = pd.DataFrame(taxa_list)\n",
    "taxa_df.sort_values(['taxon_group', 'verbatim_name'], inplace=True)\n",
    "taxa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa_df.to_csv(taxa_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add pbdb data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa_df = pd.read_csv(taxa_file, dtype=str)\n",
    "log_df(taxa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genus_dft = pd.DataFrame(taxa_df['genus name'].unique(), columns=['genus name'])\n",
    "\n",
    "log_df(genus_dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in genus_df.iterrows():\n",
    "    if pd.notna(row['pbdb_taxon_id']):\n",
    "        continue\n",
    "        \n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    if index % 50 == 0:\n",
    "        print(index, end=' ')\n",
    "\n",
    "        \n",
    "    url =  PBDB_TAXA_NAME +  row['genus name']\n",
    "        \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()[\"records\"]\n",
    "        if len(data) == 1:\n",
    "            genus_df.at[index, f'pbdb_taxon_id'] = str(data[0][\"taxon_no\"])\n",
    "            genus_df.at[index, f'pbdb_taxon_name'] = data[0][\"taxon_name\"]\n",
    "            genus_df.at[index, f'pbdb_taxon_rank'] = data[0][\"taxon_rank\"]\n",
    "            \n",
    "            round = 0\n",
    "            get_parent_taxa(genus_df, data[0][\"parent_no\"], data[0][\"taxon_rank\"], round, index, None)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df(genus_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genus_df.to_csv(genus_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create taxa list with pbdb info for the PIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genus_df = pd.read_csv(genus_file, dtype= str)\n",
    "log_df(genus_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unapproved_df = pd.read_csv(taxa_file)\n",
    "\n",
    "log_df(unapproved_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(unapproved_df, genus_df, \n",
    "                     on = 'genus name', \n",
    "                     how='left',\n",
    "                     indicator='_merge_pbdb')\n",
    "\n",
    "log_df(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['name'] = np.nan\n",
    "merged_df['Comment'] = np.nan\n",
    "merged_df['Notes (change to Internal only notes?)'] = np.nan\n",
    "merged_df['Any taxon above genus'] = np.nan\n",
    "merged_df['subgenera modifier'] = np.nan\n",
    "merged_df['subgenera name'] = np.nan\n",
    "merged_df['comments'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.reindex(columns=[\n",
    "    'taxon_group', 'verbatim_name',  'name',\n",
    "    'Comment', 'Notes (change to Internal only notes?)',\n",
    "    'Any taxon above genus', \n",
    "    'genus modifier', 'genus name', \n",
    "    'subgenera modifier','subgenera name', \n",
    "    'species modifier',  'species name',\n",
    "    'subspecies modifier', 'subspecies name',\n",
    "    'non-taxa descriptor', \n",
    "    'comments',\n",
    "    'pbdb_taxon_id', 'pbdb_taxon_name','pbdb_taxon_rank', \n",
    "    'family_taxon_id', 'family_taxon_name',\n",
    "    'order_taxon_id', 'order_taxon_name', \n",
    "    'class_taxon_id', 'class_taxon_name', \n",
    "    'phylum_taxon_id', 'phylum_taxon_name',\n",
    "    'kingdom_taxon_id', 'kingdom_taxon_name', \n",
    "    'unranked clade_taxon_id', 'unranked clade_taxon_name',\n",
    "\n",
    "])\n",
    "\n",
    "merged_df.sort_values(by=['taxon_group', 'verbatim_name'], inplace=True)\n",
    "\n",
    "log_df(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[merged_df['pbdb_taxon_id'].notna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[merged_df['pbdb_taxon_id'].isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(taxa_pbdb_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa_pbdb_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create csv of genus that are only a letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa_df = pd.read_csv(taxa_file, dtype=str)\n",
    "log_df(taxa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_genus = taxa_df[(taxa_df['genus name'].str.endswith('.'))]\n",
    "letter_genus = letter_genus[['taxon_group','verbatim_name', 'genus name']]\n",
    "log_df(letter_genus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_genus.to_csv(genus_letter_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
