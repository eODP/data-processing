{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize CSV columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the columns for the eODP CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "sys.path.append('../scripts/')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from normalize_data import (\n",
    "    normalize_sample_col, \n",
    "    normalize_expedition_section_cols, \n",
    "    csv_cleanup,\n",
    "    update_metadata,\n",
    "    fetch_unique_column_names,\n",
    "    append_set,\n",
    "    filter_existing_set,\n",
    "    normalize_columns,\n",
    "    add_missing_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology = 'cleaned_data/Lithology_CSV'\n",
    "lithology_meta = 'cleaned_data/metadata/Lithology_changes.csv'\n",
    "\n",
    "micropal_1 = 'cleaned_data/Micropal_CSV_1'\n",
    "micropal_meta_1 = 'cleaned_data/metadata/Micropal_1_changes.csv'\n",
    "\n",
    "micropal_2 = 'cleaned_data/Micropal_CSV_2'\n",
    "micropal_meta_2 = 'cleaned_data/metadata/Micropal_2_changes.csv'\n",
    "\n",
    "micropal_3 = 'cleaned_data/Micropal_CSV_3'\n",
    "micropal_meta_3 = 'cleaned_data/metadata/Micropal_3_changes.csv'\n",
    "\n",
    "micropal_4 = 'cleaned_data/Micropal_CSV_revised'\n",
    "micropal_meta_4 = 'cleaned_data/metadata/Micropal_revised_changes.csv'\n",
    "\n",
    "all_lims = [\n",
    "    'cleaned_data/Lithology_CSV',\n",
    "    'cleaned_data/Micropal_CSV_1',\n",
    "    'cleaned_data/Micropal_CSV_2',\n",
    "    'cleaned_data/Micropal_CSV_3',\n",
    "    'cleaned_data/Micropal_CSV_revised'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_path = micropal_4\n",
    "metadata_file = micropal_meta_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in all_lims:\n",
    "    raw_csvs = glob.glob(f\"{directory}/*.csv\")\n",
    "\n",
    "    for path in raw_csvs:\n",
    "        df = pd.read_csv(path, dtype=str)\n",
    "        df = csv_cleanup(df, path)\n",
    "        df.to_csv(path, index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize expedition..section columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read each Lithology CSV to check if expedition..section columns exist. Overwrite existing Lithology CSV if columns need to be added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>taxon_group</th>\n",
       "      <th>add_expedition_section_cols</th>\n",
       "      <th>update_sample_col</th>\n",
       "      <th>update_top_bottom</th>\n",
       "      <th>add_missing_cols</th>\n",
       "      <th>clean_up_taxa_values</th>\n",
       "      <th>fix_expedition_aw_cols</th>\n",
       "      <th>add_extra_sample_data</th>\n",
       "      <th>clean_up_taxa_metadata_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>363-U1482A-Benthic_Forams.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>320_U1336A_Nannofossils_2.csv</td>\n",
       "      <td>nannofossils</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>363-U1482A-nannofossils.csv</td>\n",
       "      <td>nannofossils</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>375_U1518F_planktic_forams.csv</td>\n",
       "      <td>planktic_forams</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320_U1334A_Nannofossils_1.csv</td>\n",
       "      <td>nannofossils</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file      taxon_group  \\\n",
       "0   363-U1482A-Benthic_Forams.csv   benthic_forams   \n",
       "1   320_U1336A_Nannofossils_2.csv     nannofossils   \n",
       "2     363-U1482A-nannofossils.csv     nannofossils   \n",
       "3  375_U1518F_planktic_forams.csv  planktic_forams   \n",
       "4   320_U1334A_Nannofossils_1.csv     nannofossils   \n",
       "\n",
       "   add_expedition_section_cols  update_sample_col  update_top_bottom  \\\n",
       "0                         True              False              False   \n",
       "1                        False               True              False   \n",
       "2                         True              False              False   \n",
       "3                         True              False              False   \n",
       "4                        False               True              False   \n",
       "\n",
       "   add_missing_cols  clean_up_taxa_values  fix_expedition_aw_cols  \\\n",
       "0             False                 False                    True   \n",
       "1             False                  True                   False   \n",
       "2             False                  True                    True   \n",
       "3             False                 False                    True   \n",
       "4             False                  True                   False   \n",
       "\n",
       "   add_extra_sample_data  clean_up_taxa_metadata_values  \n",
       "0                  False                           True  \n",
       "1                  False                           True  \n",
       "2                  False                           True  \n",
       "3                  False                          False  \n",
       "4                  False                           True  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(metadata_file)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189, 10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_filename(file):\n",
    "    path = f\"{clean_data_path}/{file}\"\n",
    "    content = pd.read_csv(path)\n",
    "    \n",
    "    original_cols = content.columns\n",
    "    content = normalize_expedition_section_cols(content)\n",
    "    changed = list(original_cols) != list(content.columns)\n",
    "\n",
    "        \n",
    "    if changed:\n",
    "        content = csv_cleanup(content, path)\n",
    "        content.to_csv(path, index=False)\n",
    "\n",
    "    return changed\n",
    "    \n",
    "change_columns = [process_filename(file) for file in metadata['file']] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>taxon_group</th>\n",
       "      <th>add_expedition_section_cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>339_benthic_forams_U1388B_5.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324_U1348A_benthic_forams.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>339_planktic_forams_U1387C.csv</td>\n",
       "      <td>planktic_forams</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>339_benthic_forams_U1390A_6.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>341_radiolarians_U1419D.csv</td>\n",
       "      <td>radiolarians</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              file      taxon_group  \\\n",
       "0  339_benthic_forams_U1388B_5.csv   benthic_forams   \n",
       "1    324_U1348A_benthic_forams.csv   benthic_forams   \n",
       "2   339_planktic_forams_U1387C.csv  planktic_forams   \n",
       "3  339_benthic_forams_U1390A_6.csv   benthic_forams   \n",
       "4      341_radiolarians_U1419D.csv     radiolarians   \n",
       "\n",
       "   add_expedition_section_cols  \n",
       "0                        False  \n",
       "1                        False  \n",
       "2                        False  \n",
       "3                        False  \n",
       "4                         True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\"add_expedition_section_cols\": change_columns}\n",
    "new_metadata = update_metadata(metadata, dict)\n",
    "new_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata.to_csv(metadata_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Sample column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read each Lithology CSV to check if Sample column needs to be updated. Change 'Label ID' to 'Sample'. Add 'Sample' if no 'Sample' or 'Label ID' based on expedition...section columns. Overwrite existing Lithology CSV if Sample column is updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(metadata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_filename(file):\n",
    "    path = f\"{clean_data_path}/{file}\"\n",
    "    content = pd.read_csv(path)\n",
    "    \n",
    "    original_cols = content.columns\n",
    "    normalize_sample_col(content)\n",
    "    \n",
    "    changed = list(original_cols) != list(content.columns)\n",
    "    \n",
    "    if changed:\n",
    "        content = csv_cleanup(content, path)\n",
    "        content.to_csv(path, index=False)\n",
    "\n",
    "    return changed\n",
    "    \n",
    "change_columns = [process_filename(file) for file in metadata['file']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>taxon_group</th>\n",
       "      <th>add_expedition_section_cols</th>\n",
       "      <th>update_sample_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>339_benthic_forams_U1388B_5.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324_U1348A_benthic_forams.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>339_planktic_forams_U1387C.csv</td>\n",
       "      <td>planktic_forams</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>339_benthic_forams_U1390A_6.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>341_radiolarians_U1419D.csv</td>\n",
       "      <td>radiolarians</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              file      taxon_group  \\\n",
       "0  339_benthic_forams_U1388B_5.csv   benthic_forams   \n",
       "1    324_U1348A_benthic_forams.csv   benthic_forams   \n",
       "2   339_planktic_forams_U1387C.csv  planktic_forams   \n",
       "3  339_benthic_forams_U1390A_6.csv   benthic_forams   \n",
       "4      341_radiolarians_U1419D.csv     radiolarians   \n",
       "\n",
       "   add_expedition_section_cols  update_sample_col  \n",
       "0                        False              False  \n",
       "1                        False               True  \n",
       "2                        False              False  \n",
       "3                        False              False  \n",
       "4                         True              False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\"update_sample_col\": change_columns}\n",
    "new_metadata = update_metadata(metadata, dict)\n",
    "new_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata.to_csv(metadata_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Top and Bottom columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize all the Top, Top Depth, Bottom, and Bottom Depth column to have the same names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(metadata_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get top bottom columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_all = set()\n",
    "\n",
    "res=[fetch_unique_column_names(f\"{clean_data_path}/{file}\", columns_all) for file in metadata['file']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_all = set()\n",
    "top = set()\n",
    "top_depth = set()\n",
    "\n",
    "bottom_all = set()\n",
    "bottom = set()\n",
    "bottom_depth = set()\n",
    "\n",
    "extra = set()\n",
    "\n",
    "append_set(top_all, r\".*?top.*?\", columns_all)\n",
    "append_set(top_depth, r\"top depth\", columns_all)\n",
    "append_set(top, r\"top offset|top ?\\[\", columns_all)\n",
    "\n",
    "append_set(bottom_all, r\".*?bottom.*?\", columns_all)\n",
    "append_set(bottom_depth, r\"bottom depth\", columns_all)\n",
    "append_set(bottom, r\"bottom offset|bottom ?\\[\", columns_all)\n",
    "\n",
    "append_set(extra, r\"extra\", columns_all)\n",
    "extra.update(['Extra Sample ID Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Calcidiscus leptoporus', 'Top Depth [m]', 'Top [cm]'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Top [cm]'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Top Depth [m]'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bottom Depth [m]', 'Bottom [cm]'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bottom [cm]'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bottom Depth [m]'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Extra Sample ID Data'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize top bottom columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_top_bottom(file):\n",
    "    path = f\"{clean_data_path}/{file}\"\n",
    "    content = pd.read_csv(path)\n",
    "    columns = list(content.columns)\n",
    "    \n",
    "    normalized_cols = normalize_columns(top, 'Top [cm]', columns)\n",
    "    normalized_cols = normalize_columns(bottom, 'Bottom [cm]', normalized_cols)\n",
    "    normalized_cols = normalize_columns(top_depth, 'Top Depth [m]', normalized_cols)\n",
    "    normalized_cols = normalize_columns(bottom_depth, 'Bottom Depth [m]', normalized_cols)\n",
    "    normalized_cols = normalize_columns(extra, 'Extra Sample ID Data', normalized_cols)\n",
    "\n",
    "    changed = columns != normalized_cols\n",
    "    \n",
    "    if changed:\n",
    "        content.columns = normalized_cols\n",
    "        content = csv_cleanup(content, path)\n",
    "        content.to_csv(path, index=False)\n",
    "\n",
    "    return changed\n",
    "\n",
    "change_columns = [normalize_top_bottom(file) for file in metadata['file']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>taxon_group</th>\n",
       "      <th>add_expedition_section_cols</th>\n",
       "      <th>update_sample_col</th>\n",
       "      <th>update_top_bottom</th>\n",
       "      <th>add_missing_cols</th>\n",
       "      <th>clean_up_taxa_metadata_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>363-U1482A-nannofossils_revised.csv</td>\n",
       "      <td>nannofossils</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  file   taxon_group  \\\n",
       "0  363-U1482A-nannofossils_revised.csv  nannofossils   \n",
       "\n",
       "   add_expedition_section_cols  update_sample_col  update_top_bottom  \\\n",
       "0                         True              False              False   \n",
       "\n",
       "   add_missing_cols  clean_up_taxa_metadata_values  \n",
       "0             False                           True  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\"update_top_bottom\": change_columns}\n",
    "new_metadata = update_metadata(metadata, dict)\n",
    "new_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata.to_csv(metadata_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add missing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(metadata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_columns = [\n",
    "    'Top [cm]',\n",
    "    'Bottom [cm]',\n",
    "    'Top Depth [m]',\n",
    "    'Bottom Depth [m]', \n",
    "    'Sample',\n",
    "    'Exp',\n",
    "    'Site',\n",
    "    'Hole',\n",
    "    'Core',\n",
    "    'Type',\n",
    "    'Section',\n",
    "    'A/W',\n",
    "    'Extra Sample ID Data',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_columns = [add_missing_columns(f\"{clean_data_path}/{file}\", normalized_columns) for file in metadata['file']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>taxon_group</th>\n",
       "      <th>add_expedition_section_cols</th>\n",
       "      <th>update_sample_col</th>\n",
       "      <th>update_top_bottom</th>\n",
       "      <th>add_missing_cols</th>\n",
       "      <th>clean_up_taxa_metadata_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>363-U1482A-nannofossils_revised.csv</td>\n",
       "      <td>nannofossils</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  file   taxon_group  \\\n",
       "0  363-U1482A-nannofossils_revised.csv  nannofossils   \n",
       "\n",
       "   add_expedition_section_cols  update_sample_col  update_top_bottom  \\\n",
       "0                         True              False              False   \n",
       "\n",
       "   add_missing_cols  clean_up_taxa_metadata_values  \n",
       "0             False                           True  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\"add_missing_cols\": change_columns}\n",
    "new_metadata = update_metadata(metadata, dict)\n",
    "new_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata.to_csv(metadata_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
