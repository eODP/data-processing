{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize CSV columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the columns for the eODP CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from normalize_data import (\n",
    "    normalize_sample_col, \n",
    "    normalize_expedition_section_cols, \n",
    "    csv_cleanup,\n",
    "    update_metadata,\n",
    "    fetch_unique_column_names,\n",
    "    append_set,\n",
    "    filter_existing_set,\n",
    "    normalize_columns,\n",
    "    add_missing_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_file = 'cleaned_data/metadata/Lithology_changes.csv'\n",
    "clean_data_path = 'cleaned_data/Lithology_CSV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_file = 'cleaned_data/metadata/Micropal_1_changes.csv'\n",
    "clean_data_path = 'cleaned_data/Micropal_CSV_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_file = 'cleaned_data/metadata/Micropal_2_changes.csv'\n",
    "clean_data_path = 'cleaned_data/Micropal_CSV_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize expedition..section columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read each Lithology CSV to check if expedition..section columns exist. Overwrite existing Lithology CSV if columns need to be added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>taxon_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356-U1464C_benthic_forams.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>374_U1523B_benthic_forams.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>353_U1443A_nannofossils.csv</td>\n",
       "      <td>nannofossils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>369_U1513D_planktic_forams.csv</td>\n",
       "      <td>planktic_forams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>371_U1510B_planktic_forams.csv</td>\n",
       "      <td>planktic_forams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file      taxon_group\n",
       "0   356-U1464C_benthic_forams.csv   benthic_forams\n",
       "1   374_U1523B_benthic_forams.csv   benthic_forams\n",
       "2     353_U1443A_nannofossils.csv     nannofossils\n",
       "3  369_U1513D_planktic_forams.csv  planktic_forams\n",
       "4  371_U1510B_planktic_forams.csv  planktic_forams"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(metadata_file)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_filename(file):\n",
    "    path = f\"{clean_data_path}/{file}\"\n",
    "    content = pd.read_csv(path)\n",
    "    \n",
    "    original_cols = content.columns\n",
    "    content = normalize_expedition_section_cols(content)\n",
    "    changed = list(original_cols) != list(content.columns)\n",
    "\n",
    "        \n",
    "    if changed:\n",
    "        content = csv_cleanup(content, path)\n",
    "        content.to_csv(path, index=False)\n",
    "\n",
    "    return changed\n",
    "    \n",
    "change_columns = [process_filename(file) for file in metadata['file']] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>taxon_group</th>\n",
       "      <th>add_expedition_section_cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356-U1464C_benthic_forams.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>374_U1523B_benthic_forams.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>353_U1443A_nannofossils.csv</td>\n",
       "      <td>nannofossils</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>369_U1513D_planktic_forams.csv</td>\n",
       "      <td>planktic_forams</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>371_U1510B_planktic_forams.csv</td>\n",
       "      <td>planktic_forams</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file      taxon_group  \\\n",
       "0   356-U1464C_benthic_forams.csv   benthic_forams   \n",
       "1   374_U1523B_benthic_forams.csv   benthic_forams   \n",
       "2     353_U1443A_nannofossils.csv     nannofossils   \n",
       "3  369_U1513D_planktic_forams.csv  planktic_forams   \n",
       "4  371_U1510B_planktic_forams.csv  planktic_forams   \n",
       "\n",
       "   add_expedition_section_cols  \n",
       "0                         True  \n",
       "1                         True  \n",
       "2                         True  \n",
       "3                         True  \n",
       "4                         True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\"add_expedition_section_cols\": change_columns}\n",
    "new_metadata = update_metadata(metadata, dict)\n",
    "new_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata.to_csv(metadata_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Sample column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read each Lithology CSV to check if Sample column needs to be updated. Change 'Label ID' to 'Sample'. Add 'Sample' if no 'Sample' or 'Label ID' based on expedition...section columns. Overwrite existing Lithology CSV if Sample column is updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(metadata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_filename(file):\n",
    "    path = f\"{clean_data_path}/{file}\"\n",
    "    content = pd.read_csv(path)\n",
    "    \n",
    "    original_cols = content.columns\n",
    "    normalize_sample_col(content)\n",
    "    \n",
    "    changed = list(original_cols) != list(content.columns)\n",
    "    \n",
    "    if changed:\n",
    "        content = csv_cleanup(content, path)\n",
    "        content.to_csv(path, index=False)\n",
    "\n",
    "    return changed\n",
    "    \n",
    "change_columns = [process_filename(file) for file in metadata['file']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\"update_sample_col\": change_columns}\n",
    "new_metadata = update_metadata(metadata, dict)\n",
    "new_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata.to_csv(metadata_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Top and Bottom columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize all the Top, Top Depth, Bottom, and Bottom Depth column to have the same names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(metadata_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get top bottom columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_all = set()\n",
    "\n",
    "res=[fetch_unique_column_names(f\"{clean_data_path}/{file}\", columns_all) for file in metadata['file']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_all = set()\n",
    "top = set()\n",
    "top_depth = set()\n",
    "\n",
    "bottom_all = set()\n",
    "bottom = set()\n",
    "bottom_depth = set()\n",
    "\n",
    "append_set(top_all, r\".*?top.*?\", columns_all)\n",
    "append_set(top_depth, r\"top depth\", columns_all)\n",
    "append_set(top, r\"top offset|top ?\\[\", columns_all)\n",
    "\n",
    "append_set(bottom_all, r\".*?bottom.*?\", columns_all)\n",
    "append_set(bottom_depth, r\"bottom depth\", columns_all)\n",
    "append_set(bottom, r\"bottom offset|bottom ?\\[\", columns_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acarinina praetopilensis',\n",
       " 'Acarinina praetopilensis Blow, 1979',\n",
       " 'Acarinina pseudotopilensis',\n",
       " 'Acarinina pseudotopilensis Subbotina, 1953',\n",
       " 'Acarinina topilensis',\n",
       " 'Acarinina topilensis (Cushman, 1925)',\n",
       " 'Acrocubus octopylus',\n",
       " 'Acrocubus octopylus ',\n",
       " 'Artophormis barbadensis',\n",
       " 'Artophormis dominasinensis',\n",
       " 'Artophormis gracilis',\n",
       " 'Calcidiscus leptoporus',\n",
       " 'Entopyla spp.',\n",
       " 'Grammatophora spp.',\n",
       " 'Schematophora obscura',\n",
       " 'Schematophora speciosa',\n",
       " 'Top Depth [m]',\n",
       " 'Top [cm]',\n",
       " 'Zygodiscus plectopons'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Top [cm]'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Top Depth [m]'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bottom Depth [m]', 'Bottom [cm]'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bottom [cm]'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bottom Depth [m]'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize top bottom columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_top_bottom(file):\n",
    "    path = f\"{clean_data_path}/{file}\"\n",
    "    content = pd.read_csv(path)\n",
    "    columns = list(content.columns)\n",
    "    \n",
    "    normalized_cols = normalize_columns(top, 'Top [cm]', columns)\n",
    "    normalized_cols = normalize_columns(bottom, 'Bottom [cm]', normalized_cols)\n",
    "    normalized_cols = normalize_columns(top_depth, 'Top Depth [m]', normalized_cols)\n",
    "    normalized_cols = normalize_columns(bottom_depth, 'Bottom Depth [m]', normalized_cols)\n",
    "    \n",
    "    changed = columns != normalized_cols\n",
    "    \n",
    "    if changed:\n",
    "        content.columns = normalized_cols\n",
    "        content = csv_cleanup(content, path)\n",
    "        content.to_csv(path, index=False)\n",
    "\n",
    "    return changed\n",
    "\n",
    "change_columns = [normalize_top_bottom(file) for file in metadata['file']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>taxon_group</th>\n",
       "      <th>add_expedition_section_cols</th>\n",
       "      <th>update_sample_col</th>\n",
       "      <th>update_top_bottom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>363-U1482A-Benthic_Forams.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>320_U1336A_Nannofossils_2.csv</td>\n",
       "      <td>nannofossils</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>363-U1482A-nannofossils.csv</td>\n",
       "      <td>nannofossils</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>375_U1518F_planktic_forams.csv</td>\n",
       "      <td>planktic_forams</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320_U1334A_Nannofossils_1.csv</td>\n",
       "      <td>nannofossils</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file      taxon_group  \\\n",
       "0   363-U1482A-Benthic_Forams.csv   benthic_forams   \n",
       "1   320_U1336A_Nannofossils_2.csv     nannofossils   \n",
       "2     363-U1482A-nannofossils.csv     nannofossils   \n",
       "3  375_U1518F_planktic_forams.csv  planktic_forams   \n",
       "4   320_U1334A_Nannofossils_1.csv     nannofossils   \n",
       "\n",
       "   add_expedition_section_cols  update_sample_col  update_top_bottom  \n",
       "0                         True              False              False  \n",
       "1                        False               True              False  \n",
       "2                         True              False              False  \n",
       "3                         True              False              False  \n",
       "4                        False               True              False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\"update_top_bottom\": change_columns}\n",
    "new_metadata = update_metadata(metadata, dict)\n",
    "new_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata.to_csv(metadata_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add missing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(metadata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_columns = [\n",
    "    'Top [cm]',\n",
    "    'Bottom [cm]',\n",
    "    'Top Depth [m]',\n",
    "    'Bottom Depth [m]', \n",
    "    'Sample',\n",
    "    'Exp',\n",
    "    'Site',\n",
    "    'Hole',\n",
    "    'Core',\n",
    "    'Type',\n",
    "    'Section',\n",
    "    'A/W'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_columns = [add_missing_columns(f\"{clean_data_path}/{file}\", normalized_columns) for file in metadata['file']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>taxon_group</th>\n",
       "      <th>add_expedition_section_cols</th>\n",
       "      <th>update_sample_col</th>\n",
       "      <th>update_top_bottom</th>\n",
       "      <th>add_missing_cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>363-U1482A-Benthic_Forams.csv</td>\n",
       "      <td>benthic_forams</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>320_U1336A_Nannofossils_2.csv</td>\n",
       "      <td>nannofossils</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>363-U1482A-nannofossils.csv</td>\n",
       "      <td>nannofossils</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>375_U1518F_planktic_forams.csv</td>\n",
       "      <td>planktic_forams</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320_U1334A_Nannofossils_1.csv</td>\n",
       "      <td>nannofossils</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file      taxon_group  \\\n",
       "0   363-U1482A-Benthic_Forams.csv   benthic_forams   \n",
       "1   320_U1336A_Nannofossils_2.csv     nannofossils   \n",
       "2     363-U1482A-nannofossils.csv     nannofossils   \n",
       "3  375_U1518F_planktic_forams.csv  planktic_forams   \n",
       "4   320_U1334A_Nannofossils_1.csv     nannofossils   \n",
       "\n",
       "   add_expedition_section_cols  update_sample_col  update_top_bottom  \\\n",
       "0                         True              False              False   \n",
       "1                        False               True              False   \n",
       "2                         True              False              False   \n",
       "3                         True              False              False   \n",
       "4                        False               True              False   \n",
       "\n",
       "   add_missing_cols  \n",
       "0             False  \n",
       "1             False  \n",
       "2             False  \n",
       "3             False  \n",
       "4             False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\"add_missing_cols\": change_columns}\n",
    "new_metadata = update_metadata(metadata, dict)\n",
    "new_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata.to_csv(metadata_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
